# 📊 **MobileCLIP 성능 평가 및 리포팅 방법**  

## 🔹 **요약: 성능 평가 절차**
1. **데이터 준비**  
   - 학습 데이터셋과 별도로 테스트(검증)용 데이터셋을 구성.  
   - Ground Truth(정답)과 모델의 예측값을 비교.  

2. **성능 평가 지표 선정**  
   - 🔹 **텍스트-이미지 매칭 정확도** (Top-1, Top-5 Accuracy)  
   - 🔹 **Cosine Similarity** (이미지-텍스트 벡터 유사도)  
   - 🔹 **Mean Rank / Median Rank** (정확한 매칭이 몇 번째 순위로 예측되었는지)  
   - 🔹 **Retrieval Performance (Recall@K, Precision@K)**  

3. **모델 평가 코드 작성**  
   - MobileCLIP 모델을 평가하는 PyTorch 코드 구현.  

4. **결과 리포팅**  
   - 시각적으로 보기 좋게 **표, 그래프, 히트맵**으로 표현.  

---

## 🔹 **1. 데이터 준비: 평가용 데이터셋 구축**
> 📌 **모델을 학습한 데이터와 다른 데이터셋을 사용해야 공정한 평가 가능**  
> - 학습 데이터: 모델이 학습한 사진과 텍스트  
> - 평가 데이터: 학습에 사용되지 않은 새로운 사진과 텍스트  

📍 **평가용 데이터 예시 (CSV)**
```csv
image_path,text
./test_images/cat.jpg,고양이가 창가에 앉아 있다.
./test_images/dog.jpg,강아지가 공을 물고 있다.
./test_images/coffee.jpg,카페 테이블 위의 커피잔.
```

📍 **CSV 파일 로드 코드**
```python
import pandas as pd

# 평가용 데이터셋 불러오기
test_dataset = pd.read_csv("test_dataset.csv")

# 이미지 및 텍스트 전처리
test_images, test_texts = [], []
for _, row in test_dataset.iterrows():
    test_images.append(preprocess_image(row["image_path"]))
    test_texts.append(preprocess_text(row["text"]))

test_images = torch.stack(test_images)
test_texts = {key: torch.cat([t[key] for t in test_texts], dim=0) for key in test_texts[0]}
```

---

## 🔹 **2. 성능 평가 지표 선정**
MobileCLIP의 성능을 평가하기 위해 다음과 같은 지표를 사용합니다.

### ✅ 1) **텍스트-이미지 매칭 정확도 (Top-K Accuracy)**
- `Top-1 Accuracy`: 정답이 모델의 1순위 예측값과 일치하는 비율
- `Top-5 Accuracy`: 정답이 모델의 상위 5개 예측값 중 하나와 일치하는 비율  

> **📌 예제**
> - 모델이 `["강아지", "고양이", "자동차", "커피", "나무"]` 순으로 예측했을 때,  
> - 정답이 `"고양이"`라면, `Top-1 실패, Top-5 성공`

📍 **Accuracy 계산 코드**
```python
def compute_accuracy(logits_per_image, labels, top_k=1):
    """
    Top-K Accuracy 계산 함수
    """
    top_k_preds = torch.topk(logits_per_image, k=top_k, dim=-1).indices
    correct = (top_k_preds == labels.unsqueeze(1)).any(dim=-1).float().mean()
    return correct.item()

# 평가 진행
with torch.no_grad():
    logits_per_image, _ = model(test_images, test_texts)
    labels = torch.arange(len(test_images)).to(logits_per_image.device)

    top1_acc = compute_accuracy(logits_per_image, labels, top_k=1)
    top5_acc = compute_accuracy(logits_per_image, labels, top_k=5)

print(f"Top-1 Accuracy: {top1_acc:.2%}")
print(f"Top-5 Accuracy: {top5_acc:.2%}")
```

---

### ✅ 2) **Cosine Similarity (코사인 유사도)**
> - 모델이 생성한 이미지 임베딩과 텍스트 임베딩이 얼마나 유사한지 평가.  
> - `1.0`에 가까울수록 좋은 성능.

📍 **코사인 유사도 계산 코드**
```python
import torch.nn.functional as F

def compute_cosine_similarity(image_features, text_features):
    """
    이미지와 텍스트 임베딩 간의 평균 코사인 유사도 계산
    """
    cosine_sim = F.cosine_similarity(image_features, text_features)
    return cosine_sim.mean().item()

with torch.no_grad():
    image_features = model.image_encoder(test_images)
    text_features = model.text_encoder(test_texts["input_ids"], test_texts["attention_mask"])

    cosine_sim = compute_cosine_similarity(image_features, text_features)

print(f"Mean Cosine Similarity: {cosine_sim:.4f}")
```

---

### ✅ 3) **Retrieval Performance (Recall@K, Precision@K)**
- `Recall@K`: 모델이 `K`개의 후보 중 정답을 포함하는 비율
- `Precision@K`: `K`개 중 실제로 올바른 예측의 비율

📍 **Recall@K 계산 코드**
```python
def compute_recall_at_k(logits_per_image, labels, k=5):
    top_k_preds = torch.topk(logits_per_image, k=k, dim=-1).indices
    recall = (top_k_preds == labels.unsqueeze(1)).any(dim=-1).float().mean()
    return recall.item()

with torch.no_grad():
    recall_at_5 = compute_recall_at_k(logits_per_image, labels, k=5)

print(f"Recall@5: {recall_at_5:.2%}")
```

---

## 🔹 **3. 리포팅: 시각적 표현 (표 & 그래프)**
📍 **성능 결과를 보기 좋게 정리하는 방법**

```python
import pandas as pd
import matplotlib.pyplot as plt

# 평가 결과 저장
results = {
    "Metric": ["Top-1 Accuracy", "Top-5 Accuracy", "Mean Cosine Similarity", "Recall@5"],
    "Score": [top1_acc, top5_acc, cosine_sim, recall_at_5]
}

df_results = pd.DataFrame(results)

# 표로 출력
import ace_tools as tools
tools.display_dataframe_to_user(name="MobileCLIP 성능 평가 결과", dataframe=df_results)
```

📍 **막대 그래프 시각화**
```python
plt.figure(figsize=(8, 5))
plt.bar(df_results["Metric"], df_results["Score"], color=["blue", "green", "red", "purple"])
plt.ylabel("Score")
plt.title("MobileCLIP 성능 평가 결과")
plt.ylim(0, 1)
plt.show()
```

---

## 🎯 **최종 리포트 예시**
| Metric                 | Score  |
|------------------------|--------|
| Top-1 Accuracy        | 85.4%  |
| Top-5 Accuracy        | 97.2%  |
| Mean Cosine Similarity | 0.82   |
| Recall@5              | 92.5%  |

📌 **📊 그래프 예시**  
✅ `Top-1 Accuracy`가 낮다면 데이터 라벨링 개선 필요  
✅ `Cosine Similarity`가 낮다면 모델 학습이 부족 → 더 많은 데이터 필요  

---

## 🔹 **결론**
- **MobileCLIP 모델 평가 순서** ✅  
  - ① **데이터셋 준비**: 학습 데이터와 다른 평가 데이터 사용  
  - ② **성능 지표 계산**: `Top-K Accuracy`, `Cosine Similarity`, `Recall@K`  
  - ③ **시각적 리포트**: 표 & 그래프 활용  

👉 **이제 모델 성능을 수치로 비교하고, 개선 방향을 찾을 수 있습니다!** 🚀  
추가 질문이 있으면 언제든 물어보세요 😊
