```python
import argparse
import json
import os
import numpy as np
from sklearn.model_selection import StratifiedKFold
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import AutoProcessor, AutoModelForImageTextRetrieval
from peft import LoraConfig, get_peft_model
import matplotlib.pyplot as plt

class ImageTextDataset(Dataset):
    def __init__(self, data, processor):
        self.data = data
        self.processor = processor

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        image = Image.open(item['image']).convert('RGB')
        text = item['text']
        
        inputs = self.processor(
            text=text,
            images=image,
            return_tensors='pt',
            padding=True
        )
        return inputs

def create_dataset_json(root_dir, output_file):
    dataset = []
    for class_name in os.listdir(root_dir):
        class_dir = os.path.join(root_dir, class_name)
        if os.path.isdir(class_dir):
            for file in os.listdir(class_dir):
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    dataset.append({
                        'image': os.path.join(class_dir, file),
                        'text': f'a photo of {class_name}'
                    })
    with open(output_file, 'w') as f:
        json.dump(dataset, f, indent=2)

def main():
    parser = argparse.ArgumentParser(description='MobileCLIP with LoRA Training')
    parser.add_argument('--root_dir', type=str, required=True, help='Root directory of images')
    parser.add_argument('--output_dir', type=str, required=True, help='Output directory')
    parser.add_argument('--k_folds', type=int, default=5, help='Number of K-folds')
    args = parser.parse_args()

    # Create dataset.json
    dataset_file = os.path.join(args.output_dir, 'dataset.json')
    create_dataset_json(args.root_dir, dataset_file)
    
    # Load dataset
    with open(dataset_file) as f:
        dataset = json.load(f)
    
    # Prepare labels
    labels = [os.path.basename(os.path.dirname(item['image'])) for item in dataset]
    unique_labels = list(set(labels))
    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
    encoded_labels = [label_to_idx[label] for label in labels]

    # Initialize model and processor
    processor = AutoProcessor.from_pretrained("apple/mobileclip-s0")
    model = AutoModelForImageTextRetrieval.from_pretrained("apple/mobileclip-s0")
    
    # Apply LoRA
    config = LoraConfig(
        r=8,
        lora_alpha=16,
        target_modules=["query", "value"],
        lora_dropout=0.1,
        bias="none"
    )
    model = get_peft_model(model, config)
    
    # Training setup
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    # K-fold training
    skf = StratifiedKFold(n_splits=args.k_folds)
    fold_metrics = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(dataset, encoded_labels)):
        print(f'Training fold {fold+1}/{args.k_folds}')
        
        train_data = [dataset[i] for i in train_idx]
        val_data = [dataset[i] for i in val_idx]

        train_dataset = ImageTextDataset(train_data, processor)
        val_dataset = ImageTextDataset(val_data, processor)

        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=8)

        # Training loop
        for epoch in range(10):
            model.train()
            train_loss = 0
            for batch in train_loader:
                batch = {k: v.to(device) for k, v in batch.items()}
                outputs = model(**batch)
                loss = outputs.loss
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()
                train_loss += loss.item()
            
            # Validation
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for batch in val_loader:
                    batch = {k: v.to(device) for k, v in batch.items()}
                    outputs = model(**batch)
                    val_loss += outputs.loss.item()
            
            fold_metrics.append({
                'fold': fold,
                'epoch': epoch,
                'train_loss': train_loss/len(train_loader),
                'val_loss': val_loss/len(val_loader)
            })

    # Visualization
    plt.figure(figsize=(12, 5))
    for fold in range(args.k_folds):
        fold_data = [m for m in fold_metrics if m['fold'] == fold]
        plt.plot([m['train_loss'] for m in fold_data], label=f'Fold {fold+1} Train')
        plt.plot([m['val_loss'] for m in fold_data], '--', label=f'Fold {fold+1} Val')
    plt.title('Training/Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(args.output_dir, 'loss_curve.png'))
    plt.close()

if __name__ == '__main__':
    main()
```

**Key Features:**
1. **Command Line Interface**: Uses argparse for root directory and output path configuration
2. **Stratified K-Fold**: Maintains class distribution using sklearn's StratifiedKFold
3. **LoRA Implementation**: Applies Low-Rank Adaptation to MobileCLIP model
4. **Contrastive Learning**: Utilizes built-in contrastive loss from MobileCLIP model
5. **Automatic Dataset Creation**: Generates dataset.json with image-text pairs
6. **Visualization**: Produces loss curve plot showing training/validation metrics

**Usage:**
```bash
python train.py \
  --root_dir ./images \
  --output_dir ./results \
  --k_folds 5
```

**Requirements:**
```text
torch>=2.0.0
transformers>=4.30.0
peft>=0.4.0
scikit-learn>=1.2.0
matplotlib>=3.7.0
```

**Note**: 실제 구현 시 추가적인 최적화 및 하이퍼파라미터 튜닝 필요. GPU 환경에서 실행 권장.

---
Perplexity로부터의 답변: pplx.ai/share
