```python
import argparse
import json
import os
import numpy as np
from sklearn.model_selection import StratifiedKFold
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import AutoProcessor, AutoModelForImageTextRetrieval
from peft import LoraConfig, get_peft_model
import matplotlib.pyplot as plt

class ImageTextDataset(Dataset):
    def __init__(self, data, processor):
        self.data = data
        self.processor = processor

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        image = Image.open(item['image']).convert('RGB')
        text = item['text']
        
        inputs = self.processor(
            text=text,
            images=image,
            return_tensors='pt',
            padding=True
        )
        return inputs

def create_dataset_json(root_dir, output_file):
    dataset = []
    for class_name in os.listdir(root_dir):
        class_dir = os.path.join(root_dir, class_name)
        if os.path.isdir(class_dir):
            for file in os.listdir(class_dir):
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    dataset.append({
                        'image': os.path.join(class_dir, file),
                        'text': f'a photo of {class_name}'
                    })
    with open(output_file, 'w') as f:
        json.dump(dataset, f, indent=2)

def main():
    parser = argparse.ArgumentParser(description='MobileCLIP with LoRA Training')
    parser.add_argument('--root_dir', type=str, required=True, help='Root directory of images')
    parser.add_argument('--output_dir', type=str, required=True, help='Output directory')
    parser.add_argument('--k_folds', type=int, default=5, help='Number of K-folds')
    args = parser.parse_args()

    # Create dataset.json
    dataset_file = os.path.join(args.output_dir, 'dataset.json')
    create_dataset_json(args.root_dir, dataset_file)
    
    # Load dataset
    with open(dataset_file) as f:
        dataset = json.load(f)
    
    # Prepare labels
    labels = [os.path.basename(os.path.dirname(item['image'])) for item in dataset]
    unique_labels = list(set(labels))
    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
    encoded_labels = [label_to_idx[label] for label in labels]

    # Initialize model and processor
    processor = AutoProcessor.from_pretrained("apple/mobileclip-s0")
    model = AutoModelForImageTextRetrieval.from_pretrained("apple/mobileclip-s0")
    
    # Apply LoRA
    config = LoraConfig(
        r=8,
        lora_alpha=16,
        target_modules=["query", "value"],
        lora_dropout=0.1,
        bias="none"
    )
    model = get_peft_model(model, config)
    
    # Training setup
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    # K-fold training
    skf = StratifiedKFold(n_splits=args.k_folds)
    fold_metrics = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(dataset, encoded_labels)):
        print(f'Training fold {fold+1}/{args.k_folds}')
        
        train_data = [dataset[i] for i in train_idx]
        val_data = [dataset[i] for i in val_idx]

        train_dataset = ImageTextDataset(train_data, processor)
        val_dataset = ImageTextDataset(val_data, processor)

        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=8)

        # Training loop
        for epoch in range(10):
            model.train()
            train_loss = 0
            for batch in train_loader:
                batch = {k: v.to(device) for k, v in batch.items()}
                outputs = model(**batch)
                loss = outputs.loss
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()
                train_loss += loss.item()
            
            # Validation
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for batch in val_loader:
                    batch = {k: v.to(device) for k, v in batch.items()}
                    outputs = model(**batch)
                    val_loss += outputs.loss.item()
            
            fold_metrics.append({
                'fold': fold,
                'epoch': epoch,
                'train_loss': train_loss/len(train_loader),
                'val_loss': val_loss/len(val_loader)
            })

    # Visualization
    plt.figure(figsize=(12, 5))
    for fold in range(args.k_folds):
        fold_data = [m for m in fold_metrics if m['fold'] == fold]
        plt.plot([m['train_loss'] for m in fold_data], label=f'Fold {fold+1} Train')
        plt.plot([m['val_loss'] for m in fold_data], '--', label=f'Fold {fold+1} Val')
    plt.title('Training/Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(args.output_dir, 'loss_curve.png'))
    plt.close()

if __name__ == '__main__':
    main()
```

**Key Features:**
1. **Command Line Interface**: Uses argparse for root directory and output path configuration
2. **Stratified K-Fold**: Maintains class distribution using sklearn's StratifiedKFold
3. **LoRA Implementation**: Applies Low-Rank Adaptation to MobileCLIP model
4. **Contrastive Learning**: Utilizes built-in contrastive loss from MobileCLIP model
5. **Automatic Dataset Creation**: Generates dataset.json with image-text pairs
6. **Visualization**: Produces loss curve plot showing training/validation metrics

**Usage:**
```bash
python train.py \
  --root_dir ./images \
  --output_dir ./results \
  --k_folds 5
```

**Requirements:**
```text
torch>=2.0.0
transformers>=4.30.0
peft>=0.4.0
scikit-learn>=1.2.0
matplotlib>=3.7.0
```

**Note**: 실제 구현 시 추가적인 최적화 및 하이퍼파라미터 튜닝 필요. GPU 환경에서 실행 권장.

---
---
---

이미지 데이터셋을 k-fold stratified 방식으로 분할하고 각 split을 JSON 파일로 저장하는 코드를 수정해드리겠습니다. 주요 변경 사항은 k-fold 분할 구조를 JSON 파일로 저장하고 훈련/검증/테스트 췐를 명확히 구분하는 부분입니다.

```python
import argparse
import json
import os
import numpy as np
from sklearn.model_selection import StratifiedKFold, train_test_split
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import AutoProcessor, AutoModelForImageTextRetrieval
from peft import LoraConfig, get_peft_model
import matplotlib.pyplot as plt

class ImageTextDataset(Dataset):
    def __init__(self, data, processor):
        self.data = data
        self.processor = processor

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        image = Image.open(item['image']).convert('RGB')
        inputs = self.processor(
            text=item['text'],
            images=image,
            return_tensors='pt',
            padding=True
        )
        return inputs

def create_split_files(fold_dir, split_name, data):
    os.makedirs(fold_dir, exist_ok=True)
    with open(os.path.join(fold_dir, f'{split_name}.json'), 'w') as f:
        json.dump(data, f, indent=2)

def main():
    parser = argparse.ArgumentParser(description='Stratified K-fold CLIP Training')
    parser.add_argument('--root_dir', type=str, required=True)
    parser.add_argument('--output_dir', type=str, required=True)
    parser.add_argument('--k_folds', type=int, default=5)
    parser.add_argument('--test_size', type=float, default=0.2)
    args = parser.parse_args()

    # 1. 데이터셋 생성
    dataset = []
    for class_name in os.listdir(args.root_dir):
        class_dir = os.path.join(args.root_dir, class_name)
        if os.path.isdir(class_dir):
            for img_file in os.listdir(class_dir):
                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    dataset.append({
                        'image': os.path.join(class_dir, img_file),
                        'text': f'a photo of {class_name}',
                        'label': class_name
                    })

    # 2. Stratified 분할
    labels = [item['label'] for item in dataset]
    unique_labels = list(set(labels))
    label_to_idx = {label:idx for idx, label in enumerate(unique_labels)}
    
    # 초기 분할: Train/Test
    train_data, test_data = train_test_split(
        dataset, 
        test_size=args.test_size, 
        stratify=labels,
        random_state=42
    )

    # K-fold 분할
    skf = StratifiedKFold(n_splits=args.k_folds)
    fold_metrics = []
    
    # 3. 폴드별 데이터 저장
    for fold, (train_idx, val_idx) in enumerate(skf.split(
        train_data, 
        [label_to_idx[item['label']] for item in train_data]
    )):
        fold_dir = os.path.join(args.output_dir, f'fold_{fold}')
        
        # 분할 데이터 생성
        fold_train = [train_data[i] for i in train_idx]
        fold_val = [train_data[i] for i in val_idx]
        
        # JSON 파일 저장
        create_split_files(fold_dir, 'train', fold_train)
        create_split_files(fold_dir, 'val', fold_val)
        create_split_files(args.output_dir, 'test', test_data)  # 전체 테스트셋 공통 사용

        # 4. 모델 초기화
        processor = AutoProcessor.from_pretrained("apple/mobileclip-s0")
        model = AutoModelForImageTextRetrieval.from_pretrained("apple/mobileclip-s0")
        
        # LoRA 설정
        config = LoraConfig(
            r=8,
            lora_alpha=16,
            target_modules=["query", "value"],
            lora_dropout=0.1,
            bias="none"
        )
        model = get_peft_model(model, config)
        
        # 5. 데이터 로더
        train_dataset = ImageTextDataset(fold_train, processor)
        val_dataset = ImageTextDataset(fold_val, processor)
        
        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=8)

        # 6. 학습 루프 (이전 코드와 동일)
        # ... (훈련 및 검증 코드)

    # 7. 시각화 (이전 코드와 동일)
    # ... (시각화 코드)

if __name__ == '__main__':
    main()
```

**주요 개선 사항**:

1. **계층적 분할 강화**:
   - `train_test_split`으로 초기 80:20 분할 수행
   - 남은 80% 데이터에 대해 Stratified K-Fold 적용
   ```python
   train_data, test_data = train_test_split(..., stratify=labels)
   skf.split(train_data, [labels...])
   ```

2. **폴드별 데이터 관리**:
   ```bash
   output_dir/
   ├── test.json
   └── fold_0/
       ├── train.json
       └── val.json
   ```

3. **데이터 구조 명확화**:
   ```python
   {
       "image": "./images/dog/IMG_123.jpg",
       "text": "a photo of dog",
       "label": "dog"
   }
   ```

4. **재현성 보장**:
   ```python
   train_test_split(..., random_state=42)
   ```

**실행 방법**:
```bash
python train.py \
  --root_dir ./images \
  --output_dir ./kfold_dataset \
  --k_folds 5 \
  --test_size 0.2
```

이 코드는 초기 20%를 테스트셋으로 고정한 후, 남은 80%에 대해 5-fold stratified 분할을 수행합니다. 각 폴드의 train/val 분할 비율은 4:1(전체 데이터 기준 64%:16%)이 됩니다.

---

