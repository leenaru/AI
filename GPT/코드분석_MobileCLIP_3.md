# ğŸ“Œ **ì½”ë“œ ë¶„ì„ ë° ì„¤ëª… (ì¶”ê°€ íŒŒì¼ í¬í•¨)**

ì´ë²ˆì— ì—…ë¡œë“œëœ ì¶”ê°€ íŒŒì¼ë“¤ì€ MobileCLIPì˜ **Zero-shot ImageNet í‰ê°€, ë°ì´í„° ë³€í™˜ ë° ì¦ê°•(Augmentation) ê¸°ë²•**ì„ ë‹´ë‹¹í•˜ëŠ” ì½”ë“œë“¤ì…ë‹ˆë‹¤.  
ê° íŒŒì¼ì´ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ìƒì„¸íˆ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.

---

## **ğŸ“‚ ì¶”ê°€ëœ íŒŒì¼ ê°œìš”**
| íŒŒì¼ëª… | ì£¼ìš” ì—­í•  |
|--------|----------|
| `zeroshot_imagenet.py` | MobileCLIPì„ ì‚¬ìš©í•œ **Zero-shot ImageNet í‰ê°€** |
| `transforms.py` | PyTorch ê¸°ë°˜ **ë°ì´í„° ë³€í™˜(Transformations) ëª¨ë“ˆ** |
| `transforms_base.py` | ë°ì´í„° ì¦ê°•(Augmentation) ê´€ë ¨ ê¸°ë³¸ ë³€í™˜ ëª¨ìŒ |

---

# **1ï¸âƒ£ `zeroshot_imagenet.py` ë¶„ì„ (Zero-shot ImageNet í‰ê°€)**
ğŸ“Œ **ì—­í• :**  
- MobileCLIPì„ í™œìš©í•˜ì—¬ **ImageNetì—ì„œ Zero-shot í•™ìŠµëœ ëª¨ë¸ì„ í‰ê°€**
- `clip_benchmark` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©

### ğŸ”¹ **í•µì‹¬ ì½”ë“œ ë¶„ì„**
#### **(1) ì¸ì íŒŒì‹±**
```python
def parse_args(parser):
    parser.add_argument(
        "--model-arch",
        type=str,
        required=True,
        choices=['mobileclip_s0', 'mobileclip_s1', 'mobileclip_s2', 'mobileclip_b']
    )
    parser.add_argument(
        "--model-path",
        type=str,
        required=True,
    )
    return parser
```
- ì‹¤í–‰ ì‹œ **ì‚¬ìš©í•  MobileCLIP ëª¨ë¸(`--model-arch`)ê³¼ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸(`--model-path`)ë¥¼ ì…ë ¥ë°›ìŒ**  
- `mobileclip_s0`, `mobileclip_s1` ë“± ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì§€ì›

---

#### **(2) MobileCLIP ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°**
```python
def create_model(model_arch, model_path):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, _, transform = mobileclip.create_model_and_transforms(
        model_arch, pretrained=model_path
    )
    model.eval().to(device)
    return model, transform, device
```
- MobileCLIP ëª¨ë¸ì„ ë¡œë“œí•œ í›„ **ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜(`eval()`)**
- **ì´ë¯¸ì§€ ì „ì²˜ë¦¬(`transform`)ë„ í•¨ê»˜ ë°˜í™˜**

---

#### **(3) ImageNet ë°ì´í„°ì…‹ ë¡œë“œ**
```python
def create_webdataset(task, transform, data_root=None, dataset_len=None, batch_size=64, num_workers=4):
    data_folder = f"wds_{task.replace('/','-')}_test"
    if data_root is None:
        data_root = f"https://huggingface.co/datasets/djghosh/{data_folder}/tree/main"
    dataset = build_dataset(dataset_name=f"wds/{task}", root=data_root, transform=transform, split="test")
    dataloader = torch.utils.data.DataLoader(
        dataset.batched(batch_size), batch_size=None, shuffle=False, num_workers=num_workers
    )
    return dataset, dataloader
```
- `Hugging Face`ì—ì„œ ImageNet ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ í‰ê°€
- `batch_size=64`ë¡œ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¡œë”©

---

#### **(4) ëª¨ë¸ í‰ê°€ ìˆ˜í–‰**
```python
def evaluate_webdataset(task, model_arch, model_path, data_root=None, batch_size=64):
    model, transform, device = create_model(model_arch, model_path)
    dataset, dataloader = create_webdataset(task, transform, data_root, batch_size)

    zeroshot_templates = dataset.templates if hasattr(dataset, "templates") else None
    classnames = dataset.classes if hasattr(dataset, "classes") else None

    classifier = zsc.zero_shot_classifier(model, mobileclip.get_tokenizer(model_arch), classnames, zeroshot_templates, device)
    logits, target = zsc.run_classification(model, classifier, dataloader, device, amp=False)

    acc1, acc5 = zsc.accuracy(logits, target, topk=(1, 5))
    return {"acc1": acc1, "acc5": acc5}
```
- `zero_shot_classifier()`ë¥¼ ì‚¬ìš©í•˜ì—¬ MobileCLIPì„ í™œìš©í•œ **Zero-shot í•™ìŠµ í‰ê°€** ì§„í–‰  
- `top-1`ê³¼ `top-5` ì •í™•ë„(`acc1`, `acc5` ë©”íŠ¸ë¦­) ê³„ì‚°  

âœ… **ì •ë¦¬:**  
- ì´ íŒŒì¼ì€ **MobileCLIP ëª¨ë¸ì˜ Zero-shot ì„±ëŠ¥ì„ ImageNetì—ì„œ í‰ê°€**í•˜ëŠ” ì—­í• ì„ í•¨  
- í‰ê°€ ë°ì´í„°ëŠ” `Hugging Face`ì—ì„œ ë¶ˆëŸ¬ì˜¤ë©°, ëª¨ë¸ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ `top-1`ê³¼ `top-5` ì •í™•ë„ë¥¼ ê³„ì‚°  

---

# **2ï¸âƒ£ `transforms.py` ë¶„ì„ (ë°ì´í„° ë³€í™˜ ëª¨ë“ˆ)**
ğŸ“Œ **ì—­í• :**  
- `torchvision.transforms`ì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ í™•ì¥í•˜ì—¬ **ì´ë¯¸ì§€ ë³€í™˜ ë° ì¦ê°•(Augmentation)ì„ ë³´ë‹¤ ì„¸ë°€í•˜ê²Œ ì œì–´**
- `Compressible` í´ë˜ìŠ¤ë¥¼ ë„ì…í•˜ì—¬ **ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë³€í™˜ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„**

### ğŸ”¹ **í•µì‹¬ ì½”ë“œ ë¶„ì„**
#### **(1) `Compressible` í´ë˜ìŠ¤**
```python
class Compressible:
    @staticmethod
    def compress_params(params: Any) -> Any:
        return params

    @staticmethod
    def decompress_params(params: Any) -> Any:
        return params
```
- ì´ë¯¸ì§€ ë³€í™˜ì˜ ëœë¤í•œ ìš”ì†Œ(ì˜ˆ: `RandomCrop`)ë¥¼ **ë‹¤ì‹œ ì ìš©í•  ìˆ˜ ìˆë„ë¡ ë§¤ê°œë³€ìˆ˜ë¥¼ ì €ì¥ ë° ì••ì¶•í•˜ëŠ” ê¸°ëŠ¥** ì œê³µ

---

#### **(2) `Resize` ë° `CenterCrop` ë³€í™˜**
```python
class Resize(T.Resize, Compressible):
    def forward(self, img: Tensor, params: Optional[torch.Size] = None):
        img = super().forward(img)
        return img, self.size

class CenterCrop(T.CenterCrop, Compressible):
    def forward(self, img: Tensor, params: Optional[Tuple[int, int]] = None):
        img = super().forward(img)
        return img, NO_PARAM
```
- `torchvision.transforms.Resize` ë° `CenterCrop`ì„ í™•ì¥í•˜ì—¬ **ë³€í™˜ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ ê°œì„ **  
- ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • í›„, ë³€í™˜ëœ í¬ê¸°ë¥¼ ë°˜í™˜í•˜ì—¬ **ì¬ì ìš© ê°€ëŠ¥**

âœ… **ì •ë¦¬:**  
- ì´ íŒŒì¼ì€ **MobileCLIPì˜ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ë³´ë‹¤ ì„¸ë°€í•˜ê²Œ ì»¨íŠ¸ë¡¤í•˜ëŠ” ê¸°ëŠ¥**ì„ ì œê³µ  
- `Resize`, `CenterCrop`, `RandomCrop` ë“± ë³€í™˜ì´ ë‹¤ì‹œ ì ìš©ë  ìˆ˜ ìˆë„ë¡ ë§¤ê°œë³€ìˆ˜ë¥¼ ì €ì¥  

---

# **3ï¸âƒ£ `transforms_base.py` ë¶„ì„ (ê¸°ë³¸ ì´ë¯¸ì§€ ë³€í™˜)**
ğŸ“Œ **ì—­í• :**  
- `AutoAugment`, `RandAugment`, `TrivialAugmentWide` ë“±ì˜ **ë°ì´í„° ì¦ê°•(Augmentation) ê¸°ë²•ì„ í¬í•¨**
- MobileCLIP ëª¨ë¸ í•™ìŠµ ì‹œ, **ë”ìš± ê°•ë ¥í•œ ë°ì´í„° ë³€í™˜ ê¸°ëŠ¥ì„ ì§€ì›**

### ğŸ”¹ **í•µì‹¬ ì½”ë“œ ë¶„ì„**
#### **(1) AutoAugment / RandAugment**
```python
class AutoAugment(T.AutoAugment):
    def __init__(self, policy: str = "imagenet", interpolation: str = "bilinear"):
        policy = T.AutoAugmentPolicy.IMAGENET
        interpolation = INTERPOLATION_MODE_MAP[interpolation]
        super().__init__(policy=policy, interpolation=interpolation)
```
- **ìë™ ë°ì´í„° ì¦ê°•(AutoAugment)** ì ìš© (ImageNet, CIFAR, SVHN ë“± ì§€ì›)

```python
class RandAugment(T.RandAugment):
    def __init__(self, interpolation: str = "bilinear"):
        interpolation = INTERPOLATION_MODE_MAP[interpolation]
        super().__init__(interpolation=interpolation)
```
- **ëœë¤ ë°ì´í„° ì¦ê°•(RandAugment)** ì ìš©

âœ… **ì •ë¦¬:**  
- ì´ íŒŒì¼ì€ MobileCLIP í•™ìŠµì„ ìœ„í•œ **ê³ ê¸‰ ë°ì´í„° ì¦ê°•(Augmentation) ê¸°ë²•ì„ í¬í•¨**  
- `AutoAugment`, `RandAugment`ë¥¼ í™œìš©í•˜ì—¬ **ë°ì´í„° ë‹¤ì–‘ì„±ì„ ê·¹ëŒ€í™”**  

---

# **ğŸ“Œ ìµœì¢… ì •ë¦¬**
| íŒŒì¼ëª… | ì—­í•  |
|--------|------|
| `zeroshot_imagenet.py` | MobileCLIPì„ ì‚¬ìš©í•œ **Zero-shot ImageNet í‰ê°€** |
| `transforms.py` | PyTorchì˜ `torchvision.transforms`ë¥¼ í™•ì¥í•˜ì—¬ **ì´ë¯¸ì§€ ë³€í™˜ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •** |
| `transforms_base.py` | MobileCLIPì˜ **ë°ì´í„° ì¦ê°•(Augmentation) ê¸°ë²•**ì„ ì œê³µ |

---

âœ… **ê²°ë¡ :**  
- MobileCLIPì˜ **Zero-shot í•™ìŠµëœ ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ì½”ë“œ**(`zeroshot_imagenet.py`)  
- MobileCLIPì˜ **ë°ì´í„° ë³€í™˜ ë° ì¦ê°•(Augmentation) ëª¨ë“ˆ** (`transforms.py`, `transforms_base.py`)  
- í•™ìŠµ ë° í‰ê°€ ê³¼ì •ì—ì„œ **ì´ë¯¸ì§€ ë³€í™˜ì„ ì¬ì ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ êµ¬ì¡°**

ì¶”ê°€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š
