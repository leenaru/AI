# Onboarding Agent — 요구사항 & 아키텍처 (v2025-08-15)

> 음성 중심 + 카메라 프리뷰 인터랙션을 제공하는 **온디바이스 우선** 하이브리드 AI 에이전트. 디바이스에서 가능한 일은 로컬로 처리하고, 복잡한 계획/검색/지식 조회는 서버의 LangGraph 오케스트레이터로 위임. 모델 교체가 쉬운 **Model Adapter Layer**, 국가별 **정책 오버레이**, **다국어 지원**, **GraphRAG 기반 KB**를 핵심 축으로 설계.

---

## 1) 목표 & 스코프

* **주요 목적**: 카메라 프리뷰 화면에서 자연스러운 음성 대화로 업무/가이드/셋업을 수행하는 온디바이스 우선 에이전트.
* **핵심 가치**: 낮은 지연시간(로컬 처리), 개인정보 보호, 네트워크 불안정 시 **오프라인 모드** 유지, 모델/벤더 **독립성**, 비용 최소화(가능하면 온디바이스와 온프레미스 모델 사용).
* **타깃 플랫폼**: Android, iOS (각각 SpeechRecognizer / Speech framework + TTS), 서버는 FastAPI + LangGraph 기반.
* **주요 도메인 예**: IoT/가전 등록/설정 가이드, 고객 지원(FAQ/RAG), 사진 기반 확인/인증, 여행·예약형 태스크 오케스트레이션 등.

---

## 2) 대표 사용자 시나리오 (요약)

1. 사용자가 **말하기 버튼**을 누르고 기기에 요청 → 디바이스에서 **ASR(STT)** → 로컬 NLU 룰/소형 LLM으로 1차 분류.
2. "사진 첨부" 등 특정 키워드/의도가 감지되면 **카메라 앱 오픈**, 촬영 후 로컬 전처리(리사이즈·압축·익명화) → 서버 분석 필요 시 전송.
3. 서버 **LangGraph 오케스트레이터**가 정책 검사 → 계획 수립 → 도구 호출(vision/RAG/검색/업로드 등) → 응답 작성.
4. 결과는 다국어 번역 → **TTS**로 음성 출력, 필요 시 UI 오버레이(체크리스트/버튼)로 후속 액션 유도.
5. 네트워크 오류 시, 온디바이스 백오프·큐잉 → 회복 시 자동 재전송.

---

## 3) 기능 요구사항 (Functional)

* **온디바이스 처리**

  * Gemma 3n 등 소형 LLM으로 짧은 답변/룰 보강 NLU/후처리.
  * 디바이스 STT/TTS, 카메라 프리뷰, 이미지 전처리(축소/모자이크/텍스트 추출 등).
  * 기기 리소스 연동: 위치, 센서, 파일, 네트워크 상태.
* **서버 처리 (오케스트레이션)**

  * LangGraph 기반 **상태 기계**로 단계적 계획/도구 실행.
  * **Model Adapter Layer**: vLLM ↔ Ollama ↔ Remote LLM 교체/혼합 라우팅.
  * **GraphRAG+FAISS**: 문서/FAQ 인제스트 → 임베딩/그래프 생성 → 하이브리드 검색 + **rerank 적용**.
  * **번역 매니저**: 다국어 입·출력 정규화.
  * **정책/가드레일**: 국가별 규정·금칙어·동의 플로우 오버레이.
* **지식 베이스(KB)**

  * 버전 관리되는 문서 세트, 파이프라인(크롤/ETL → 청크 → 임베딩 → 그래프).
  * 소스 메타데이터(버전, 날짜, 출처)와 신뢰 신호 관리.
* **클라이언트 액션 루프**

  * 서버가 요구한 **행동(Action)**(카메라 열기, 옵션 선택 등)을 앱이 실행 → 결과를 다시 서버로 회신.
* **관측/운영**

  * 트레이스/로그/지표(Prometheus/Grafana), 헬스체크, 자동 페일오버.

---

## 4) 비기능 요구사항 (Non‑Functional)

* **지연시간 목표**: 로컬 반응(버튼→피드백) < 100ms, ASR partial < 300ms, TTS 시작 < 700ms, 서버 왕복 < 1.5s (p95).
* **가용성**: 서버 측 이중화(멀티 모델 백엔드), 네트워크 단절 시 필수 기능 로컬 유지.
* **보안/프라이버시**: 전송/저장 암호화, 최소 수집, PII 마스킹, 리텐션 정책.
* **휴대성**: 모델/DB/클라우드 벤더 종속 최소화, IaC/Helm으로 재현 가능.
* **비용 최소화 원칙**:

  * 온디바이스 우선 처리(ASR/TTS/NLU/간단 응답)로 서버 호출과 토큰 소모 최소화.
  * **캐시 우선**: 의미 캐시(semantic cache)와 임베딩 재사용으로 중복 연산/호출 감소.
  * **토큰 다이어트**: 프롬프트 클리핑/요약, Max Input Tokens, 엄격한 stop 조건, 시스템/도구 메시지 템플릿화.
  * **모델 라우팅**: 품질 임계값을 만족하는 **최저 비용 모델** 우선, 실패 시 상향 페일오버.
  * **배치/오프피크**: 임베딩·인제스트는 배치/야간 처리, 인덱스 증분 업데이트로 피크 비용 억제.
  * **스토리지 등급화**: 원문은 저비용 스토리지, 핫 인덱스는 로컬 디스크/메모리 매핑(FAISS) 사용.
  * **관측 기반 통제**: 요청당 비용, 토큰/초, 캐시 히트율 모니터링 → 자동 한도/스로틀.

---

## 5) 전체 아키텍처 개요 (Component)

<img width="1812" height="907" alt="image" src="https://github.com/user-attachments/assets/22fa3ae9-96e6-4847-a90a-4a0410ae6629" />

```plantuml
@startuml
skinparam componentStyle rectangle
skinparam wrapWidth 200
skinparam maxMessageSize 80

package "Mobile (Android/iOS)" {
  [UI (Camera Preview + Mic)] as UI
  [ASR/TTS] as Speech
  [On-Device LLM (Gemma 3n)] as ODL
  [Action Runner\n(Camera, Picker, Sensors)] as AR
}

package "Edge/Server" {
  [API Gateway (FastAPI)] as API
  [Orchestrator (LangGraph)] as ORCH
  [Policy Engine\n(Country Overlays)] as POLICY
  [Translation Manager] as TR
  [RAG Service (GraphRAG+FAISS)] as RAG
  [Model Adapter Layer] as ADPT
  [Vision Analysis] as VISION
}

package "Model Backends" {
  [vLLM] as VLLM
  [Ollama] as OLLAMA
  [Remote LLM] as RLLM
}

package "Data Layer" {
  database "FAISS (Vector Index)" as VDB
  file "GraphRAG Parquet (Edges/Units)" as PARQ
  database "Graph DB (optional)" as GDB
  database "Redis (Checkpointer)" as REDIS
  database "Postgres (State/Jobs)" as PG
  [Object Storage (S3)] as S3
}

package "Ops" {
  [Prometheus] as PROM
  [Grafana] as GRAF
}

UI -down-> Speech
UI -down-> AR
UI --> API : HTTPS gRPC/REST
Speech --> ODL : NLU assist / short gen
ODL --> UI : intent, redaction, prompt clips
ODL --> API : optional HTTPS (gated/queued)
AR --> UI

API --> ORCH
ORCH --> POLICY
ORCH --> TR
ORCH --> RAG
ORCH --> ADPT
ORCH --> VISION

RAG --> VDB
RAG --> PARQ
RAG --> GDB : optional

ORCH --> REDIS : state
ORCH --> PG : tasks
VISION --> S3 : temp artifacts

ADPT --> VLLM
ADPT --> OLLAMA
ADPT --> RLLM

API --> PROM
ORCH --> PROM
PROM --> GRAF
@enduml
```

---

## 6) 컴포넌트 상세 설계

### 6.1 Mobile App

* **UI**: 카메라 프리뷰 상단에 음성 입력 버튼, 결과 오버레이(텍스트/아이콘/체크리스트)
* **ASR/TTS**: iOS Speech / Android SpeechRecognizer + 네이티브 TTS. 스트리밍 partial 결과 제공.
* **On-Device LLM**: gemma-3n(quant)로 NLU 룰 보강, 짧은 응답, 후처리.
* **Action Runner**: 카메라/파일/위치/권한 처리. 서버 지시에 따라 단계별 UX 진행.
* **오프라인 모드**: 요청 큐/재전송, 로컬 캐시.

#### 6.1.1 On-Device LLM 역할(정확한 범위)

* **의도 1차 판별(Gate)**: 규칙(정규식/슬롯) + 소형 LLM을 혼합해 **의도/슬롯 추출** 및 **신뢰도 점수** 산출. 임계치 이상이면 로컬 처리 또는 요약·정규화 후 서버로 **승격(escalate)**.
* **프롬프트 다이어트 & 마스킹**: 불필요 맥락 제거, 개인정보/얼굴/연락처 등 **로컬 마스킹** 후 전송.
* **간단 응답/후처리**: 짧은 Q\&A, 확인/요약, 버튼 라벨 생성, TTS 친화 문장화.
* **캐시/프리페치 보조**: 의미 캐시 조회, 최근 히트 재사용, 서버 호출 전 **쿼리 정제**.
* **오프라인 대체**: 네트워크 불가 시 제한 모드로 **로컬-only 시나리오** 제공.

##### 의도 게이팅 기준(예)

* `intent_score < τ_low` → 로컬 후속 질문 유도(모호성 해소)
* `τ_low ≤ intent_score < τ_high` → **서버 승격**(LangGraph 계획 필요)
* `intent_score ≥ τ_high` & `no_external_tools` → 로컬 처리(짧은 답변/액션)

##### 게이팅 의사코드

```python
def local_gate(nlu, text, ctx):
    intent, score, slots = nlu.infer(text)
    redacted = redact(text)
    if score < 0.45:
        return {"mode":"clarify_local","prompt":clarify(intent)}
    if requires_tools(intent, slots) or score < 0.75:
        return {"mode":"escalate","api_payload":clip(redacted, slots)}
    return {"mode":"answer_local","text":short_answer(intent, slots)}
```

> **메모**: 다이어그램에 `ODL → API` 경로를 **(optional, gated/queued)** 로 추가했습니다. 기본 원칙은 **UI 네트워크 레이어가 소유**하되, ODL 모듈이 게이팅 결과에 따라 호출을 **트리거**하거나 **백그라운드 큐**를 사용할 수 있습니다.

### 6.2 API Gateway (FastAPI)

* 엔드포인트(예시):

  * `POST /chat` : 멀티모달 요청(텍스트, 오디오, 이미지 메타) 수신
  * `POST /actions/result` : 클라이언트 액션 결과 수신
  * `POST /vision/analyze` : 이미지/비디오 프레임 분석
  * `POST /speech/stt` , `POST /speech/tts`
  * `GET /healthz`, `GET /readyz`
* 인증: OAuth2/JWT, 디바이스 바인딩.

### 6.3 Orchestrator (LangGraph)

* **Checkpointer**: Redis/Postgres. 세션/스텝 레벨 상태 공유.
* **노드**(예): Input → PolicyGuard → DetectIntent → Plan → ToolSelect → Execute → Aggregate → Draft → Validate → Translate → Respond
* **에러 처리**: 재시도/보정 프롬프트/대안 경로.

### 6.4 Model Adapter Layer

* **라우팅 규칙**(YAML): 모델 가중치, 토큰 한도, 비용, 지연, 헬스 점수, 국가 규제 태그.
* **백엔드**: vLLM(서빙 성능), Ollama(호환/로컬), Remote LLM(선택적).
* **헬스체크 & 오토 페일오버**: 회로차단기, 지연/오류율 기반 스위칭.

### 6.5 RAG / KB (GraphRAG 하이브리드)

* **스토리지 계층**: 기본은 **GraphRAG Parquet(파일 기반)** 으로 시작 → 필요 시 **Graph DB(옵션: JanusGraph/NebulaGraph)** 로 확장.
* **인덱스**: FAISS(HNSW/IVF‑PQ) + BM25(Sparse) + 그래프 컨텍스트(Parquet/GraphDB).
* **인덱싱 파이프라인**: 원문 → 정제/분할 → **그래프화**(개체/관계/문서‑개체) → **Parquet 출력**(edges, units) → **요약/유닛 생성** → **임베딩** → **FAISS 인덱스 생성/증분 업데이트**.
* **검색/병합**: 질의 시 **GraphRAG 검색**(Parquet 또는 GraphDB) + **FAISS 검색**을 **랭크/병합**.

  * 가중치 재랭크: `score = α·sim_dense + β·bm25 + γ·graph_score (+ δ·recency)`
  * 필요 시 Cross‑Encoder 재랭크는 **top‑M**에만 적용.
* **트러블슈팅 지식**: 트러블슈팅 QA/룰은 Parquet 그래프 유닛과 FAISS 벡터 모두에 인덱싱.

  * 일치 항목이 있으면 해당 근거와 함께 즉시 답변.
  * 일치 항목이 없으면 **HITL 경로**로 전환(§6.9 참조).

### 6.6 Policy Engine

* 국가별 금칙/민감 카테고리, 연령/동의 플로우, 로깅 레벨.
* 정책 위반 시 대안 제시, 감사 로깅, 경보(Webhook) 훅(향후 확장).

### 6.7 Translation Manager

* 다국어 입출력 정규화(ko/en/ja/…); 사용자 선호 언어 유지.
* 시스템/도구 응답의 용어 일관성 보장(용어집/스타일 가이드).

### 6.8 Vision Analysis

* 라이트웨이트 모델(텍스트 검출, QR/바코드, 기기 식별), 서버/온디바이스 선택적.
* 민감 영역 마스킹(얼굴/주소) 옵션.

### 6.9 HITL 트러블슈팅 업데이트(운영 자동화)

* **조건**: 사용자의 질문에 대한 정합 답변이 KB(Parquet/FAISS)에 **부재**일 때.
* **흐름**:

  1. ORCH가 **/kb/propose** 이벤트 생성(질문, 콘텍스트, 추천 초안, 메타 포함).
  2. **Slack 알림**(채널: #ops-kb)으로 카드 전송(Approve/Reject 버튼).
  3. 담당자 검토 후 **승인(Approve)** → 파이프라인 트리거:

     * 메타 YAML 작성(`topic, product, severity, owner, source, locale, status`)
     * 콘텐츠(답변/근거) 저장 → **Parquet 파티션 증분 업데이트**
     * **FAISS add\_with\_ids**(증분 삽입) 또는 소량 리빌드
     * 인덱스 버전 증가 및 감사 로깅
  4. **거절(Reject)** 시 사유 기록, ORCH가 대체 답변/에스컬레이션 안내.
* **상태**: `proposed → approved → published`(배포)
* **지표**: 제안→승인 리드타임, 재질문률, HITL 비율.

---

## 7) 상태 & 데이터 설계

* **ConversationState**(요약):

```json
{
  "session_id": "uuid",
  "user_profile": {"locale":"ko-KR","consents":{...}},
  "policy_context": {"country":"KR","age_gate":true},
  "turn": {"input": {"text":...,"audio_ref":...,"image_refs":[...]},
            "intent": {"label":..., "score":...},
            "plan": [...],
            "tools_used": [...],
            "kb_hits": [...],
            "draft": ..., "final": ...},
  "history_head": "vector_cache_key",
  "metrics": {"latency_ms":...,"backend":"vllm"}
}
```

* **Checkpointer**: 그래프 스텝 단위로 직렬화, 재시도/재개 지원.

---

## 8) 배포 토폴로지 & DevOps

* **개발/로컬**: docker-compose (API, ORCH, VDB, PARQ, GDB(opt), REDIS, PG, Grafana, Prometheus, Ollama/vLLM 선택).
* **스테이징/운영**: Kubernetes + Helm 차트 (HPA, PDB, Secret/ConfigMap, Ingress, ServiceMonitor).
* **CI/CD**: GitHub Actions → 포매팅/테스트 → 컨테이너 빌드 → 헬름 패키징/서명 → 환경별 릴리스.
* **관측/알림**: RED/USE, 지연/오류율/용량 대시보드, 경보 룰 + **Slack 앱/웹훅/인터랙션 엔드포인트**.
* **작업자(Worker)**: 인덱스 증분 업데이트 잡(Parquet 파티션/FAISS add\_with\_ids), 재시도/백오프.

---

## 9) API 설계(요약)

* `POST /chat`
  **Req**: `{ text|audio|image_refs, device_ctx, locale }`
  **Res**: `{ messages[], actions[], tts_url?, citations[] }`
* `POST /actions/result`
  **Req**: `{ action_id, payload, attachments[] }` → **Res**: `{ status }`
* `POST /vision/analyze`
  **Req**: `{ image|video_frame, tasks:[ocr,detect,qr] }` → **Res**: `{ results }`

### 9.1 운영/HITL & Slack 연동

* `POST /kb/propose` : ORCH→Ops, 제안 카드 생성(질문, 초안, 근거, 메타 YAML)
* `POST /kb/approve` : Slack 액션 웹훅(승인) → 인덱싱 잡 트리거
* `POST /kb/reject` : Slack 액션 웹훅(거절) → 사유 저장
* `POST /slack/actions` : 인터랙티브 콜백 수신 엔드포인트
* `POST /kb/reindex` : (관리용) 특정 파티션/문서 증분 리빌드

### 9.2 KB 메타 YAML 스키마(예)

```yaml
id: kb-2025-08-15-001
locale: ko-KR
topic: "device-troubleshooting"
product: "SmartAC-9000"
severity: "high"   # low|medium|high|critical
source: "ops"
owner: "@seungho"
status: "proposed"  # proposed|approved|published
created_at: "2025-08-15T07:30:00Z"
updated_at: "2025-08-15T07:30:00Z"
tags: ["wifi", "pairing", "error-code:E12"]
summary: "Wi‑Fi 페어링 중 E12 오류 해결 절차"
answer: |
  1) 공유기 2.4GHz 전용 SSID 사용…
  2) 앱에서 기기 리셋 버튼 5초…
units:
  - id: unit-1
    text: "E12: DHCP 실패 시 라우터 재시작"
  - id: unit-2
    text: "AP 모드 진입: 전원 버튼 10초…"
```

---

## 10) LangGraph 오케스트레이션 (개략)

```python
state = {
  "input": {},
  "intent": None,
  "plan": [],
  "kb_hits": [],
  "response": None,
}

# 노드들: Input -> Guard -> Intent -> Plan -> ToolExec -> Synthesize -> Translate -> Respond
```

* **Intent**: 로컬 규칙(정규식/키워드/슬롯) + 소형 LLM + 서버 분류기(모호할 때).
* **Plan/ToolExec**: Vision / RAG / 서드파티 API / Client Action 지시.
* **Synthesize**: 모델 어댑터로 라우팅, 근거 인용.

---

## 11) GraphRAG 파이프라인 (요약)

1. **수집**: 파일/크롤/웹훅 → S3 임시 보관
2. **정제/분할**: 규칙 기반/문서 유형별 파서
3. **그래프화**: 개체/관계/문서‑개체 추출 → **GraphRAG Parquet**(edges, units) 출력
4. **유닛 요약/임베딩**: 요약 단위(Units) 생성 → 멀티링구얼 임베딩
5. **FAISS 인덱스**: HNSW/IVF‑PQ 생성, **증분 업데이트** 지원
6. **질의**: GraphRAG 검색(Parquet/옵션 GraphDB) + FAISS 검색 동시 실행
7. **랭크/병합**: 가중치 Re‑rank(α,β,γ\[,δ]) → 선택적 Cross‑Encoder(top‑M)
8. **배포**: 인덱스 버전 태깅, 원복 포인트 생성
9. **HITL 반영**: Slack 승인 시 파티션 증분 업데이트(§6.9)

---

## 12) 실패/복구 시나리오

* **모델 서버 장애**: Adapter가 vLLM→Ollama로 페일오버, 회로차단기 열림.
* **네트워크 단절**: 요청 로컬 큐/재시도, 핵심 기능(ASR/TTS/간단 응답) 로컬 유지.
* **비정상 입력**: 정책 엔진이 차단 후 대안 메시지/가이드 제공.

---

## 13) 보안/프라이버시

* 전송(TLS)/저장(디스크 암호화), 최소 수집, PII 마스킹(얼굴/주소/연락처), 옵트인 기반 텔레메트리.
* 감사 로깅 + 관리 콘솔 접근 통제, 키/시크릿 로테이션.

---

## 14) 테스트 전략

* 단위/통합/시나리오 E2E(음성·카메라 포함), 지연/부하 테스트, 안전성/레드팀 시나리오, 다국어 회귀 테스트.

---

## 15) 운영 대시보드(예)

* **모델 라우팅 현황**(vLLM vs Ollama 비중, 오류율), **RAG 히트율**, **p95 지연**, **정책 차단 건수**, **액션 루프 성공률**.
* **비용 지표**: 요청당 비용(₩/req), 입력/출력 토큰, 캐시 히트율, 인덱스 빌드 시간/주기, 재랭커 적용률(top-M 비율).

---

## 16) 시퀀스 다이어그램

### 16.1 음성+카메라 액션 루프

<img width="791" height="489" alt="image" src="https://github.com/user-attachments/assets/a7904eae-4096-4112-8c3d-6b064b1456c6" />

```plantuml
@startuml
actor User
participant "Mobile UI" as M
participant "ASR/TTS" as ST
participant "On-Device LLM" as ODL
participant "API" as API
participant "Orchestrator" as ORCH

User -> M: 누르고 말하기
M -> ST: 음성 캡처 시작 (partial)
ST -> M: partial text
M -> ODL: text for gating
ODL -> M: intent/slots, decision
alt escalate
  ODL -> API: /chat {text_clipped, intent, slots}
  API -> ORCH: route
  ORCH -> M: Action("open_camera")
else local answer
  ODL -> M: short answer
end
@enduml
```

### 16.2 모델 페일오버(vLLM→Ollama)

<img width="544" height="366" alt="image" src="https://github.com/user-attachments/assets/ebea5861-f31b-4103-8d0b-b78a3c34215d" />

```plantuml
@startuml
participant Client
participant API
participant ORCH
participant ADPT
participant vLLM
participant Ollama

Client -> API: /chat
API -> ORCH
ORCH -> ADPT: generate(request)
ADPT -> vLLM: health+infer
vLLM --> ADPT: timeout/error
ADPT -> Ollama: infer(fallback)
Ollama --> ADPT: ok
ADPT --> ORCH: text
ORCH --> API: response
API --> Client: 200 OK
@enduml
```

### 16.3 GraphRAG 조회(Parquet 우선 + 선택적 GraphDB)

<img width="741" height="463" alt="image" src="https://github.com/user-attachments/assets/ff4a981d-248a-4abd-8f0a-2d6ea158a3c0" />

```plantuml
@startuml
participant ORCH
participant RAG
database "FAISS Index" as VDB
database "Parquet (Edges/Units)" as PARQ
database "GraphDB (opt)" as GDB

ORCH -> RAG: query(q, k=8)
RAG -> VDB: knn(q)
VDB --> RAG: top_k_dense
RAG -> PARQ: graph_lookup(q)
PARQ --> RAG: subgraph/units
RAG -> GDB: k-hop (optional)
GDB --> RAG: neighbors
note right of RAG
  weighted merge:
  score = α*dense + β*bm25 + γ*graph + δ*recency
  then optional cross-encoder on top-M
end note
RAG --> ORCH: passages + graph_context + citations
@enduml
```

### 16.4 로컬 의도 게이트 & 에스컬레이트

<img width="745" height="443" alt="image" src="https://github.com/user-attachments/assets/c3f45541-7a63-42d9-89a6-4916f0ee6723" />

```plantuml
@startuml
actor User
participant UI
participant ODL
participant API

User -> UI: "사진 첨부해서 에러 해결 도와줘"
UI -> ODL: transcript
ODL -> ODL: intent=troubleshooting, score=0.68
ODL -> UI: propose action: open_camera
alt score < τ_high
  ODL -> API: /chat {intent, slots, clipped_text}
  API --> UI: server plan (needs image)
else score ≥ τ_high & no external tools
  ODL --> UI: local guidance steps
end
@enduml
```

---

## 17) 모델 라우터 설정(YAML 스니펫)

```yaml
models:
  - name: vllm_qwen72b
    provider: vllm
    max_tokens: 4096
    cost_weight: 0.7
    latency_weight: 0.2
    quality_weight: 0.1
    health_endpoint: http://vllm:8000/health
  - name: ollama_llama3_8b
    provider: ollama
    max_tokens: 2048
    cost_weight: 0.4
    latency_weight: 0.4
    quality_weight: 0.2
    health_endpoint: http://ollama:11434/health
routing:
  rules:
    - if: "country == 'KR' and task == 'faq'"
      prefer: [ollama_llama3_8b, vllm_qwen72b]
    - if: "latency_p95 > 1500 or error_rate > 5%"
      action: failover
```

### 17.1 RAG 설정(YAML 스니펫)

```yaml
rag:
  graph_store:
    type: parquet
    path: s3://kb/parquet/  # 또는 로컬 경로
    optional_graphdb:
      enabled: false
      provider: janusgraph   # 또는 nebulagraph
      uri: bolt://graph:7687
  index:
    type: faiss
    factory: hnsw   # 또는 ivf_pq
    params:
      dim: 768
      hnsw:
        M: 32
        efConstruction: 200
      ivf_pq:
        nlist: 4096
        m: 16
        nbits: 8
  ingest:
    unit_summary: true   # 텍스트 요약→유닛 생성
    incremental: true
  retrieval:
    k_dense: 40
    k_sparse: 40    # 선택: BM25 비활성화 시 0
    k_graph: 2
    merge:
      formula: "alpha*dense + beta*bm25 + gamma*graph + delta*recency"
      weights:
        alpha: 0.55
        beta: 0.25
        gamma: 0.15
        delta: 0.05
      cross_encoder:
        enabled: true
        top_m: 10
        model: "bge-reranker-v2-m3"
  cost_controls:
    semantic_cache: true
    dedupe_near_duplicates: true
    max_passages: 12
```

### 17.2 로컬 의도 게이트 설정(YAML)

```yaml
local_gate:
  thresholds:
    low: 0.45
    high: 0.75
  require_tools:
    troubleshooting: true
    device_registration: true
    smalltalk: false
  redact:
    pii: ["phone", "address", "email"]
  clip:
    max_chars: 800
    keep_slots: true
```

---

## 18) 로드맵/To‑Do (요약)

* ReactFlow 기반 **시나리오 GUI** ↔ YAML DSL 상호 변환 안정화
* 온디바이스 STT/TTS 스트리밍 품질 튜닝(바람소리/잔향 억제)
* Vision 경량 모델 온디바이스 이전 옵션 검증(Core ML / NNAPI)
* GraphRAG 품질 평가 파이프라인/대시보드 연동
* 정책/안전 대안응답 템플릿 정교화

---

**참고**: 이 문서는 향후 세부 구현(코드/헬름/CI 파이프라인)과 함께 버전 태그를 증가시키며 관리합니다.
