"""
IoT AI ì±—ë´‡ - LangGraph ë§ˆì´í¬ë¡œì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° êµ¬í˜„
"""

from typing import Dict, List, Optional, Any, TypedDict, Annotated, Literal
from enum import Enum
import asyncio
import json
import uuid
from datetime import datetime
from dataclasses import dataclass, asdict
from pydantic import BaseModel, Field

from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolExecutor
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig

import logging
from redis import Redis
from kafka import KafkaProducer, KafkaConsumer
import httpx
from sqlalchemy.ext.asyncio import AsyncSession

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# Core Types and States
# =============================================================================

class WorkflowType(str, Enum):
    DEVICE_REGISTRATION = "device_registration"
    TROUBLESHOOTING = "troubleshooting"
    MANUAL_GUIDANCE = "manual_guidance"
    PURCHASE_GUIDE = "purchase_guide"

class ProcessingTier(str, Enum):
    EDGE = "edge"
    FOG = "fog" 
    CLOUD = "cloud"

class ConversationState(TypedDict):
    """ì „ì²´ ëŒ€í™” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ë©”ì¸ ìƒíƒœ í´ë˜ìŠ¤"""
    # ê¸°ë³¸ ì •ë³´
    conversation_id: str
    user_id: str
    session_id: str
    timestamp: str
    
    # ì‚¬ìš©ì ì…ë ¥ ë° ì˜ë„
    user_input: str
    intent: str
    confidence: float
    processing_tier: ProcessingTier
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
    conversation_history: List[Dict[str, Any]]
    current_workflow: Optional[WorkflowType]
    workflow_state: str
    step_count: int
    
    # ë””ë°”ì´ìŠ¤ ë° í™˜ê²½ ì •ë³´
    device_info: Dict[str, Any]
    environment_context: Dict[str, Any]
    user_preferences: Dict[str, Any]
    
    # ì²˜ë¦¬ ê²°ê³¼
    extracted_entities: Dict[str, Any]
    retrieved_knowledge: List[Dict[str, Any]]
    generated_response: str
    required_actions: List[Dict[str, Any]]
    
    # ìƒíƒœ ê´€ë¦¬
    error_state: Optional[str]
    retry_count: int
    processing_metadata: Dict[str, Any]
    
    # ì›Œí¬í”Œë¡œìš°ë³„ ì „ìš© ìƒíƒœ
    device_registration_state: Optional[Dict[str, Any]]
    troubleshooting_state: Optional[Dict[str, Any]]
    manual_guidance_state: Optional[Dict[str, Any]]
    purchase_guide_state: Optional[Dict[str, Any]]

# =============================================================================
# Base Orchestrator and Workflow Registry
# =============================================================================

class WorkflowRegistry:
    """ì›Œí¬í”Œë¡œìš° ë“±ë¡ ë° ê´€ë¦¬"""
    
    def __init__(self):
        self.workflows: Dict[WorkflowType, StateGraph] = {}
        self.workflow_configs: Dict[WorkflowType, Dict] = {}
        
    def register_workflow(self, workflow_type: WorkflowType, 
                         graph: StateGraph, config: Dict = None):
        """ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš° ë“±ë¡"""
        self.workflows[workflow_type] = graph
        self.workflow_configs[workflow_type] = config or {}
        logger.info(f"Registered workflow: {workflow_type}")
        
    def get_workflow(self, workflow_type: WorkflowType) -> Optional[StateGraph]:
        """ì›Œí¬í”Œë¡œìš° ì¡°íšŒ"""
        return self.workflows.get(workflow_type)
        
    def list_workflows(self) -> List[WorkflowType]:
        """ë“±ë¡ëœ ì›Œí¬í”Œë¡œìš° ëª©ë¡"""
        return list(self.workflows.keys())

class MicroworkflowOrchestrator:
    """ë§ˆì´í¬ë¡œì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self, 
                 redis_client: Redis,
                 kafka_producer: KafkaProducer,
                 model_router: 'AdaptiveModelRouter',
                 knowledge_engine: 'KnowledgeEngine'):
        
        self.workflow_registry = WorkflowRegistry()
        self.redis_client = redis_client
        self.kafka_producer = kafka_producer
        self.model_router = model_router
        self.knowledge_engine = knowledge_engine
        
        # ì²´í¬í¬ì¸í„° ì„¤ì • (ìƒíƒœ ì €ì¥ìš©)
        self.checkpointer = MemorySaver()
        
        # ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        self._initialize_workflows()
        
    def _initialize_workflows(self):
        """ëª¨ë“  ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ë° ë“±ë¡"""
        # ê° ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ë“±ë¡
        device_reg_workflow = DeviceRegistrationWorkflow(self)
        self.workflow_registry.register_workflow(
            WorkflowType.DEVICE_REGISTRATION,
            device_reg_workflow.build_graph()
        )
        
        troubleshooting_workflow = TroubleshootingWorkflow(self)
        self.workflow_registry.register_workflow(
            WorkflowType.TROUBLESHOOTING,
            troubleshooting_workflow.build_graph()
        )
        
        manual_guide_workflow = ManualGuidanceWorkflow(self)
        self.workflow_registry.register_workflow(
            WorkflowType.MANUAL_GUIDANCE,
            manual_guide_workflow.build_graph()
        )
        
        purchase_guide_workflow = PurchaseGuideWorkflow(self)
        self.workflow_registry.register_workflow(
            WorkflowType.PURCHASE_GUIDE,
            purchase_guide_workflow.build_graph()
        )
        
        logger.info("All workflows initialized successfully")
    
    async def process_user_request(self, 
                                 user_input: str,
                                 user_id: str,
                                 device_info: Dict,
                                 session_id: Optional[str] = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ìš”ì²­ ì²˜ë¦¬ ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
        
        # ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì‚¬ìš©
        if not session_id:
            session_id = str(uuid.uuid4())
            
        conversation_id = f"{user_id}_{session_id}_{int(datetime.now().timestamp())}"
        
        # ì´ˆê¸° ìƒíƒœ ìƒì„±
        initial_state = ConversationState(
            conversation_id=conversation_id,
            user_id=user_id,
            session_id=session_id,
            timestamp=datetime.now().isoformat(),
            user_input=user_input,
            intent="",
            confidence=0.0,
            processing_tier=ProcessingTier.CLOUD,
            conversation_history=[],
            current_workflow=None,
            workflow_state="start",
            step_count=0,
            device_info=device_info,
            environment_context={},
            user_preferences={},
            extracted_entities={},
            retrieved_knowledge=[],
            generated_response="",
            required_actions=[],
            error_state=None,
            retry_count=0,
            processing_metadata={},
            device_registration_state=None,
            troubleshooting_state=None,
            manual_guidance_state=None,
            purchase_guide_state=None
        )
        
        try:
            # 1. ì˜ë„ ë¶„ë¥˜ ë° ì›Œí¬í”Œë¡œìš° ì„ íƒ
            workflow_type = await self._classify_intent_and_select_workflow(initial_state)
            initial_state["current_workflow"] = workflow_type
            
            # 2. ì„ íƒëœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            workflow_graph = self.workflow_registry.get_workflow(workflow_type)
            if not workflow_graph:
                raise ValueError(f"Workflow not found: {workflow_type}")
                
            # 3. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            config = RunnableConfig(
                configurable={
                    "thread_id": session_id,
                    "checkpoint_id": conversation_id
                }
            )
            
            final_state = await workflow_graph.ainvoke(
                initial_state, 
                config=config,
                checkpointer=self.checkpointer
            )
            
            # 4. ê²°ê³¼ ì²˜ë¦¬ ë° ë°˜í™˜
            result = await self._format_response(final_state)
            
            # 5. ì´ë²¤íŠ¸ ë°œí–‰ (ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§ìš©)
            await self._publish_workflow_event(final_state)
            
            return result
            
        except Exception as e:
            logger.error(f"Error processing request: {str(e)}")
            return await self._handle_error(initial_state, e)
    
    async def _classify_intent_and_select_workflow(self, state: ConversationState) -> WorkflowType:
        """ì˜ë„ ë¶„ë¥˜ ë° ì›Œí¬í”Œë¡œìš° ì„ íƒ"""
        
        user_input = state["user_input"].lower()
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (ì‹¤ì œë¡œëŠ” LLM ê¸°ë°˜ ë¶„ë¥˜ ì‚¬ìš©)
        if any(keyword in user_input for keyword in ["ë“±ë¡", "ì—°ê²°", "ì„¤ì •", "ì…‹ì—…", "register", "connect"]):
            return WorkflowType.DEVICE_REGISTRATION
        elif any(keyword in user_input for keyword in ["ë¬¸ì œ", "ì—ëŸ¬", "ì•ˆë¨", "ê³ ì¥", "trouble", "error", "fix"]):
            return WorkflowType.TROUBLESHOOTING
        elif any(keyword in user_input for keyword in ["ì‚¬ìš©ë²•", "ë§¤ë‰´ì–¼", "ì–´ë–»ê²Œ", "manual", "how", "guide"]):
            return WorkflowType.MANUAL_GUIDANCE
        elif any(keyword in user_input for keyword in ["êµ¬ë§¤", "ì¶”ì²œ", "í˜¸í™˜", "buy", "recommend", "compatible"]):
            return WorkflowType.PURCHASE_GUIDE
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ ë§¤ë‰´ì–¼ ê°€ì´ë“œë¡œ ë¶„ë¥˜
            return WorkflowType.MANUAL_GUIDANCE
    
    async def _format_response(self, state: ConversationState) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ í¬ë§·íŒ…"""
        return {
            "conversation_id": state["conversation_id"],
            "response": state["generated_response"],
            "actions": state["required_actions"],
            "workflow_type": state["current_workflow"],
            "workflow_state": state["workflow_state"],
            "processing_metadata": state["processing_metadata"],
            "success": state["error_state"] is None
        }
    
    async def _publish_workflow_event(self, state: ConversationState):
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì´ë²¤íŠ¸ ë°œí–‰"""
        event = {
            "event_type": "workflow_completed",
            "conversation_id": state["conversation_id"],
            "workflow_type": state["current_workflow"],
            "success": state["error_state"] is None,
            "step_count": state["step_count"],
            "processing_time": state["processing_metadata"].get("total_time", 0),
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            self.kafka_producer.send("workflow_events", value=json.dumps(event))
        except Exception as e:
            logger.warning(f"Failed to publish event: {str(e)}")
    
    async def _handle_error(self, state: ConversationState, error: Exception) -> Dict[str, Any]:
        """ì—ëŸ¬ ì²˜ë¦¬"""
        error_response = {
            "conversation_id": state["conversation_id"],
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "actions": [{"type": "retry", "description": "ë‹¤ì‹œ ì‹œë„"}],
            "workflow_type": state.get("current_workflow"),
            "error": str(error),
            "success": False
        }
        
        # ì—ëŸ¬ ë¡œê·¸ ë° ë©”íŠ¸ë¦­
        logger.error(f"Workflow error: {error}")
        
        return error_response

# =============================================================================
# Device Registration Workflow
# =============================================================================

class DeviceRegistrationWorkflow:
    """IoT ê¸°ê¸° ë“±ë¡ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, orchestrator: MicroworkflowOrchestrator):
        self.orchestrator = orchestrator
    
    def build_graph(self) -> StateGraph:
        """ê¸°ê¸° ë“±ë¡ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±"""
        
        workflow = StateGraph(ConversationState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("validate_prerequisites", self.validate_prerequisites)
        workflow.add_node("scan_environment", self.scan_environment) 
        workflow.add_node("check_compatibility", self.check_compatibility)
        workflow.add_node("provide_setup_guidance", self.provide_setup_guidance)
        workflow.add_node("verify_connection", self.verify_connection)
        workflow.add_node("handle_setup_errors", self.handle_setup_errors)
        workflow.add_node("finalize_registration", self.finalize_registration)
        
        # ì—£ì§€ ì •ì˜ (ì¡°ê±´ë¶€ ë¼ìš°íŒ…)
        workflow.set_entry_point("validate_prerequisites")
        
        workflow.add_conditional_edges(
            "validate_prerequisites",
            self.should_continue_prerequisites,
            {
                "continue": "scan_environment",
                "missing_info": "provide_setup_guidance",
                "error": "handle_setup_errors"
            }
        )
        
        workflow.add_edge("scan_environment", "check_compatibility")
        
        workflow.add_conditional_edges(
            "check_compatibility", 
            self.should_continue_compatibility,
            {
                "compatible": "provide_setup_guidance",
                "incompatible": "handle_setup_errors",
                "need_more_info": "provide_setup_guidance"
            }
        )
        
        workflow.add_edge("provide_setup_guidance", "verify_connection")
        
        workflow.add_conditional_edges(
            "verify_connection",
            self.should_continue_verification,
            {
                "success": "finalize_registration", 
                "failed": "handle_setup_errors",
                "retry": "provide_setup_guidance"
            }
        )
        
        workflow.add_conditional_edges(
            "handle_setup_errors",
            self.should_continue_error_handling,
            {
                "retry": "provide_setup_guidance",
                "escalate": END,
                "complete": "finalize_registration"
            }
        )
        
        workflow.add_edge("finalize_registration", END)
        
        return workflow
    
    async def validate_prerequisites(self, state: ConversationState) -> ConversationState:
        """ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ê²€ì¦"""
        logger.info("Validating prerequisites for device registration")
        
        state["step_count"] += 1
        state["workflow_state"] = "validating_prerequisites"
        
        # ê¸°ê¸° ì •ë³´ ì¶”ì¶œ
        device_info = state["device_info"]
        user_input = state["user_input"]
        
        # í•„ìˆ˜ ì •ë³´ ì²´í¬ë¦¬ìŠ¤íŠ¸
        required_info = {
            "device_type": None,
            "device_model": None,  
            "network_type": None,
            "mobile_app_version": device_info.get("app_version"),
            "os_version": device_info.get("os_version")
        }
        
        # LLMì„ ì‚¬ìš©í•œ ì—”í‹°í‹° ì¶”ì¶œ
        extracted_entities = await self._extract_device_entities(user_input)
        required_info.update(extracted_entities)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["extracted_entities"] = required_info
        state["device_registration_state"] = {
            "prerequisites_checked": True,
            "missing_info": [k for k, v in required_info.items() if v is None],
            "validation_time": datetime.now().isoformat()
        }
        
        return state
    
    async def scan_environment(self, state: ConversationState) -> ConversationState:
        """ë„¤íŠ¸ì›Œí¬ í™˜ê²½ ìŠ¤ìº”"""
        logger.info("Scanning network environment")
        
        state["step_count"] += 1
        state["workflow_state"] = "scanning_environment"
        
        # í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ (ì‹¤ì œë¡œëŠ” ë””ë°”ì´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ì •ë³´ ì‚¬ìš©)
        environment_info = {
            "wifi_networks": ["HomeWiFi", "GuestNetwork"],
            "bluetooth_available": True,
            "location_permission": True,
            "network_quality": "good"
        }
        
        state["environment_context"] = environment_info
        state["device_registration_state"]["environment_scanned"] = True
        
        return state
    
    async def check_compatibility(self, state: ConversationState) -> ConversationState:
        """ê¸°ê¸° í˜¸í™˜ì„± í™•ì¸"""
        logger.info("Checking device compatibility")
        
        state["step_count"] += 1
        state["workflow_state"] = "checking_compatibility"
        
        device_type = state["extracted_entities"].get("device_type")
        
        # ì§€ì‹ë² ì´ìŠ¤ì—ì„œ í˜¸í™˜ì„± ì •ë³´ ê²€ìƒ‰
        compatibility_query = f"í˜¸í™˜ì„± {device_type} ì•± ë²„ì „ ìš”êµ¬ì‚¬í•­"
        knowledge_results = await self.orchestrator.knowledge_engine.search(
            query=compatibility_query,
            filters={"category": "compatibility"}
        )
        
        state["retrieved_knowledge"] = knowledge_results
        
        # í˜¸í™˜ì„± íŒì • (ê°„ì†Œí™”ëœ ë¡œì§)
        compatibility_score = 0.9  # ì‹¤ì œë¡œëŠ” ë³µì¡í•œ ë¡œì§
        
        state["device_registration_state"]["compatibility_score"] = compatibility_score
        state["device_registration_state"]["compatibility_checked"] = True
        
        return state
    
    async def provide_setup_guidance(self, state: ConversationState) -> ConversationState:
        """ì„¤ì • ê°€ì´ë“œ ì œê³µ"""
        logger.info("Providing setup guidance")
        
        state["step_count"] += 1
        state["workflow_state"] = "providing_guidance"
        
        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = {
            "device_info": state["extracted_entities"],
            "environment": state["environment_context"],
            "knowledge": state["retrieved_knowledge"]
        }
        
        # LLMì„ í†µí•œ ì‘ë‹µ ìƒì„±
        guidance_prompt = self._build_guidance_prompt(context)
        response = await self.orchestrator.model_router.generate_response(
            prompt=guidance_prompt,
            context=context
        )
        
        state["generated_response"] = response["text"]
        
        # í•„ìš”í•œ ì•¡ì…˜ ì •ì˜
        actions = [
            {
                "type": "camera_open",
                "description": "QR ì½”ë“œ ìŠ¤ìº”ì„ ìœ„í•´ ì¹´ë©”ë¼ë¥¼ ì—´ì–´ì£¼ì„¸ìš”",
                "required": True
            },
            {
                "type": "wifi_settings",
                "description": "WiFi ì„¤ì • í˜ì´ì§€ë¡œ ì´ë™",
                "required": True
            }
        ]
        
        state["required_actions"] = actions
        state["device_registration_state"]["guidance_provided"] = True
        
        return state
    
    async def verify_connection(self, state: ConversationState) -> ConversationState:
        """ì—°ê²° í™•ì¸"""
        logger.info("Verifying device connection")
        
        state["step_count"] += 1
        state["workflow_state"] = "verifying_connection"
        
        # ì—°ê²° ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë””ë°”ì´ìŠ¤ë¡œë¶€í„° ë°›ìŒ)
        connection_status = {
            "connected": True,
            "signal_strength": 85,
            "connection_type": "wifi",
            "verification_time": datetime.now().isoformat()
        }
        
        state["device_registration_state"]["connection_status"] = connection_status
        
        if connection_status["connected"]:
            state["generated_response"] = "ê¸°ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! ì—°ê²° ìƒíƒœë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤..."
        else:
            state["generated_response"] = "ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤."
        
        return state
    
    async def handle_setup_errors(self, state: ConversationState) -> ConversationState:
        """ì„¤ì • ì—ëŸ¬ ì²˜ë¦¬"""
        logger.info("Handling setup errors")
        
        state["step_count"] += 1
        state["workflow_state"] = "handling_errors"
        
        # ì—ëŸ¬ ë¶„ì„ ë° í•´ê²°ë°©ì•ˆ ì œì‹œ
        error_context = state["device_registration_state"]
        
        if not error_context.get("connection_status", {}).get("connected"):
            error_type = "connection_failed"
            solution = "ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”. WiFi ë¹„ë°€ë²ˆí˜¸ê°€ ì •í™•í•œì§€, ì‹ í˜¸ ê°•ë„ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
        else:
            error_type = "unknown_error"
            solution = "ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê³ ê°ì§€ì›íŒ€ì— ì—°ê²°í•´ë“œë¦´ê¹Œìš”?"
        
        state["generated_response"] = solution
        state["device_registration_state"]["error_type"] = error_type
        state["device_registration_state"]["solution_provided"] = True
        
        return state
    
    async def finalize_registration(self, state: ConversationState) -> ConversationState:
        """ë“±ë¡ ì™„ë£Œ"""
        logger.info("Finalizing device registration")
        
        state["step_count"] += 1
        state["workflow_state"] = "completed"
        
        # ë“±ë¡ ì™„ë£Œ ì²˜ë¦¬
        registration_result = {
            "device_id": f"device_{uuid.uuid4().hex[:8]}",
            "registration_time": datetime.now().isoformat(),
            "success": True
        }
        
        state["device_registration_state"]["registration_result"] = registration_result
        state["generated_response"] = f"""
        ğŸ‰ ê¸°ê¸° ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!
        
        ê¸°ê¸° ID: {registration_result['device_id']}
        ë“±ë¡ ì‹œê°„: {registration_result['registration_time']}
        
        ì´ì œ ëª¨ë“  ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!
        """
        
        state["required_actions"] = [
            {
                "type": "show_success",
                "description": "ë“±ë¡ ì™„ë£Œ í™”ë©´ í‘œì‹œ",
                "data": registration_result
            }
        ]
        
        return state
    
    # ì¡°ê±´ í•¨ìˆ˜ë“¤
    def should_continue_prerequisites(self, state: ConversationState) -> str:
        missing_info = state["device_registration_state"].get("missing_info", [])
        if len(missing_info) > 2:
            return "missing_info"
        elif state.get("error_state"):
            return "error"
        else:
            return "continue"
    
    def should_continue_compatibility(self, state: ConversationState) -> str:
        score = state["device_registration_state"].get("compatibility_score", 0)
        if score > 0.8:
            return "compatible"
        elif score > 0.5:
            return "need_more_info" 
        else:
            return "incompatible"
    
    def should_continue_verification(self, state: ConversationState) -> str:
        connection = state["device_registration_state"].get("connection_status", {})
        if connection.get("connected"):
            return "success"
        elif state["retry_count"] < 3:
            return "retry"
        else:
            return "failed"
    
    def should_continue_error_handling(self, state: ConversationState) -> str:
        error_type = state["device_registration_state"].get("error_type")
        if error_type == "connection_failed" and state["retry_count"] < 2:
            return "retry"
        elif error_type == "unknown_error":
            return "escalate"
        else:
            return "complete"
    
    async def _extract_device_entities(self, user_input: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ê¸°ê¸° ê´€ë ¨ ì—”í‹°í‹° ì¶”ì¶œ"""
        # ì‹¤ì œë¡œëŠ” NER ëª¨ë¸ ë˜ëŠ” LLM ì‚¬ìš©
        entities = {}
        
        if "ìŠ¤ë§ˆíŠ¸" in user_input:
            entities["device_type"] = "smart_device"
        if "ì¹´ë©”ë¼" in user_input:
            entities["device_type"] = "camera"
        if "ì „êµ¬" in user_input:
            entities["device_type"] = "smart_bulb"
            
        return entities
    
    def _build_guidance_prompt(self, context: Dict) -> str:
        """ì„¤ì • ê°€ì´ë“œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        return f"""
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ IoT ê¸°ê¸° ë“±ë¡ì„ ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
        
        ê¸°ê¸° ì •ë³´: {context['device_info']}
        ë„¤íŠ¸ì›Œí¬ í™˜ê²½: {context['environment']}
        í˜¸í™˜ì„± ì •ë³´: {context['knowledge']}
        
        ì‚¬ìš©ìê°€ ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹¨ê³„ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
        """

# =============================================================================
# Troubleshooting Workflow  
# =============================================================================

class TroubleshootingWorkflow:
    """íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, orchestrator: MicroworkflowOrchestrator):
        self.orchestrator = orchestrator
    
    def build_graph(self) -> StateGraph:
        """íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±"""
        
        workflow = StateGraph(ConversationState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze_symptoms", self.analyze_symptoms)
        workflow.add_node("run_diagnostics", self.run_diagnostics)
        workflow.add_node("rank_solutions", self.rank_solutions)
        workflow.add_node("provide_step_by_step_fix", self.provide_step_by_step_fix)
        workflow.add_node("verify_resolution", self.verify_resolution)
        workflow.add_node("escalate_support", self.escalate_support)
        
        # ì—£ì§€ ì •ì˜
        workflow.set_entry_point("analyze_symptoms")
        workflow.add_edge("analyze_symptoms", "run_diagnostics")
        workflow.add_edge("run_diagnostics", "rank_solutions")
        workflow.add_edge("rank_solutions", "provide_step_by_step_fix")
        
        workflow.add_conditional_edges(
            "provide_step_by_step_fix",
            self.should_verify_or_continue,
            {
                "verify": "verify_resolution",
                "continue": "provide_step_by_step_fix"
            }
        )
        
        workflow.add_conditional_edges(
            "verify_resolution",
            self.should_escalate_or_complete,
            {
                "resolved": END,
                "retry": "provide_step_by_step_fix", 
                "escalate": "escalate_support"
            }
        )
        
        workflow.add_edge("escalate_support", END)
        
        return workflow
    
    async def analyze_symptoms(self, state: ConversationState) -> ConversationState:
        """ì¦ìƒ ë¶„ì„"""
        logger.info("Analyzing troubleshooting symptoms")
        
        state["step_count"] += 1
        state["workflow_state"] = "analyzing_symptoms"
        
        # ì¦ìƒ ë¶„ì„ì„ ìœ„í•œ LLM í˜¸ì¶œ
        symptoms_prompt = f"""
        ì‚¬ìš©ìê°€ ë³´ê³ í•œ ë‹¤ìŒ ë¬¸ì œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
        "{state['user_input']}"
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
        - ì£¼ìš” ì¦ìƒ
        - ê°€ëŠ¥í•œ ì›ì¸ë“¤
        - ì‹¬ê°ë„ (1-10)
        - ê´€ë ¨ ì»´í¬ë„ŒíŠ¸
        """
        
        analysis_result = await self.orchestrator.model_router.generate_response(
            prompt=symptoms_prompt,
            context={"user_input": state["user_input"]}
        )
        
        state["troubleshooting_state"] = {
            "symptoms_analysis": analysis_result,
            "severity": 5,  # ê¸°ë³¸ê°’
            "analyzed_at": datetime.now().isoformat()
        }
        
        return state
    
    async def run_diagnostics(self, state: ConversationState) -> ConversationState:
        """ì§„ë‹¨ ì‹¤í–‰"""
        logger.info("Running diagnostics")
        
        state["step_count"] += 1
        state["workflow_state"] = "running_diagnostics"
        
        # ì§„ë‹¨ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‹¤í–‰
        diagnostic_results = {
            "network_connectivity": True,
            "device_power": True,
            "app_version": "latest",
            "permissions": True,
            "device_compatibility": True
        }
        
        state["troubleshooting_state"]["diagnostic_results"] = diagnostic_results
        
        return state
    
    async def rank_solutions(self, state: ConversationState) -> ConversationState:
        """í•´ê²°ë°©ì•ˆ ìˆœìœ„ ë§¤ê¸°ê¸°"""
        logger.info("Ranking potential solutions")
        
        state["step_count"] += 1 
        state["workflow_state"] = "ranking_solutions"
        
        # ì§€ì‹ë² ì´ìŠ¤ì—ì„œ í•´ê²°ë°©ì•ˆ ê²€ìƒ‰
        problem_context = state["troubleshooting_state"]["symptoms_analysis"]
        solutions = await self.orchestrator.knowledge_engine.search(
            query=f"í•´ê²°ë°©ì•ˆ {problem_context}",
            filters={"category": "troubleshooting"}
        )
        
        # í•´ê²°ë°©ì•ˆ ìˆœìœ„ ë§¤ê¸°ê¸° (ì„±ê³µë¥  ê¸°ë°˜)
        ranked_solutions = [
            {
                "id": 1,
                "title": "ë„¤íŠ¸ì›Œí¬ ì¬ì—°ê²°",
                "success_rate": 0.85,
                "difficulty": "easy",
                "estimated_time": "2-3ë¶„"
            },
            {
                "id": 2, 
                "title": "ì•± ì¬ì‹œì‘",
                "success_rate": 0.70,
                "difficulty": "easy", 
                "estimated_time": "1ë¶„"
            },
            {
                "id": 3,
                "title": "ê¸°ê¸° ì „ì› ì¬ë¶€íŒ…",
                "success_rate": 0.90,
                "difficulty": "medium",
                "estimated_time": "5ë¶„"
            }
        ]
        
        state["troubleshooting_state"]["ranked_solutions"] = ranked_solutions
        state["troubleshooting_state"]["current_solution_index"] = 0
        
        return state
    
    async def provide_step_by_step_fix(self, state: ConversationState) -> ConversationState:
        """ë‹¨ê³„ë³„ í•´ê²° ê°€ì´ë“œ ì œê³µ"""
        logger.info("Providing step-by-step fix")
        
        state["step_count"] += 1
        state["workflow_state"] = "providing_fix"
        
        current_index = state["troubleshooting_state"]["current_solution_index"]
        solutions = state["troubleshooting_state"]["ranked_solutions"]
        
        if current_index >= len(solutions):
            state["workflow_state"] = "escalation_needed"
            state["generated_response"] = "ì œì‹œëœ ëª¨ë“  í•´ê²°ë°©ì•ˆì„ ì‹œë„í–ˆì§€ë§Œ ë¬¸ì œê°€ ì§€ì†ë©ë‹ˆë‹¤. ì „ë¬¸ ì§€ì›íŒ€ì— ì—°ê²°í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            return state
        
        current_solution = solutions[current_index]
        
        # ë‹¨ê³„ë³„ ê°€ì´ë“œ ìƒì„±
        fix_prompt = f"""
        ë‹¤ìŒ í•´ê²°ë°©ì•ˆì— ëŒ€í•œ ìì„¸í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
        
        í•´ê²°ë°©ì•ˆ: {current_solution['title']}
        ì˜ˆìƒ ì†Œìš”ì‹œê°„: {current_solution['estimated_time']}
        ë‚œì´ë„: {current_solution['difficulty']}
        
        ì‚¬ìš©ìê°€ ì‰½ê²Œ ë”°ë¼í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì¸ ë‹¨ê³„ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        fix_guide = await self.orchestrator.model_router.generate_response(
            prompt=fix_prompt,
            context=current_solution
        )
        
        state["generated_response"] = fix_guide["text"]
        state["troubleshooting_state"]["current_fix_guide"] = fix_guide
        
        # í•„ìš”í•œ ì•¡ì…˜ ì •ì˜
        actions = []
        if current_solution["title"] == "ë„¤íŠ¸ì›Œí¬ ì¬ì—°ê²°":
            actions = [
                {
                    "type": "wifi_settings",
                    "description": "WiFi ì„¤ì •ìœ¼ë¡œ ì´ë™",
                    "required": True
                }
            ]
        elif current_solution["title"] == "ì•± ì¬ì‹œì‘":
            actions = [
                {
                    "type": "app_restart",
                    "description": "ì•± ì¬ì‹œì‘",
                    "required": True
                }
            ]
        
        state["required_actions"] = actions
        
        return state
    
    async def verify_resolution(self, state: ConversationState) -> ConversationState:
        """í•´ê²° í™•ì¸"""
        logger.info("Verifying problem resolution")
        
        state["step_count"] += 1
        state["workflow_state"] = "verifying_resolution"
        
        # ì‚¬ìš©ì í”¼ë“œë°± ëŒ€ê¸° (ì‹¤ì œë¡œëŠ” í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ìŒ)
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        resolution_status = {
            "resolved": False,  # ì‹¤ì œë¡œëŠ” ì‚¬ìš©ì í”¼ë“œë°±
            "user_satisfaction": 0,
            "additional_issues": None
        }
        
        state["troubleshooting_state"]["resolution_status"] = resolution_status
        
        if not resolution_status["resolved"]:
            # ë‹¤ìŒ í•´ê²°ë°©ì•ˆìœ¼ë¡œ ì´ë™
            current_index = state["troubleshooting_state"]["current_solution_index"]
            state["troubleshooting_state"]["current_solution_index"] = current_index + 1
            state["generated_response"] = "í˜„ì¬ ë°©ë²•ìœ¼ë¡œ í•´ê²°ë˜ì§€ ì•Šì•˜ë„¤ìš”. ë‹¤ë¥¸ í•´ê²°ë°©ì•ˆì„ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤."
        else:
            state["generated_response"] = "ë¬¸ì œê°€ í•´ê²°ë˜ì–´ ë‹¤í–‰ì…ë‹ˆë‹¤! ì¶”ê°€ë¡œ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
        
        return state
    
    async def escalate_support(self, state: ConversationState) -> ConversationState:
        """ì§€ì›íŒ€ ì—ìŠ¤ì»¬ë ˆì´ì…˜"""
        logger.info("Escalating to human support")
        
        state["step_count"] += 1
        state["workflow_state"] = "escalated"
        
        # ì—ìŠ¤ì»¬ë ˆì´ì…˜ í‹°ì¼“ ìƒì„±
        ticket_info = {
            "ticket_id": f"TK-{uuid.uuid4().hex[:8].upper()}",
            "priority": "medium",
            "category": "technical_support",
            "attempted_solutions": [s["title"] for s in state["troubleshooting_state"]["ranked_solutions"]],
            "user_context": state["device_info"],
            "created_at": datetime.now().isoformat()
        }
        
        state["troubleshooting_state"]["escalation_ticket"] = ticket_info
        state["generated_response"] = f"""
        ì „ë¬¸ ì§€ì›íŒ€ì— ì—°ê²°í•´ë“œë ¸ìŠµë‹ˆë‹¤.
        
        ğŸ« ì§€ì› í‹°ì¼“: {ticket_info['ticket_id']}
        â° ì˜ˆìƒ ì‘ë‹µì‹œê°„: 1-2ì‹œê°„
        ğŸ“ ê¸´ê¸‰í•œ ê²½ìš°: ê³ ê°ì„¼í„° 1588-0000
        
        ì§€ì›íŒ€ì—ì„œ ê³§ ì—°ë½ë“œë¦´ ì˜ˆì •ì…ë‹ˆë‹¤.
        """
        
        state["required_actions"] = [
            {
                "type": "show_ticket_info",
                "description": "ì§€ì› í‹°ì¼“ ì •ë³´ í‘œì‹œ",
                "data": ticket_info
            }
        ]
        
        return state
    
    # ì¡°ê±´ í•¨ìˆ˜ë“¤
    def should_verify_or_continue(self, state: ConversationState) -> str:
        if state["workflow_state"] == "escalation_needed":
            return "verify"
        return "verify"
    
    def should_escalate_or_complete(self, state: ConversationState) -> str:
        resolution_status = state["troubleshooting_state"].get("resolution_status", {})
        
        if resolution_status.get("resolved"):
            return "resolved"
        
        current_index = state["troubleshooting_state"]["current_solution_index"]
        max_solutions = len(state["troubleshooting_state"]["ranked_solutions"])
        
        if current_index >= max_solutions:
            return "escalate"
        else:
            return "retry"

# =============================================================================
# Manual Guidance Workflow
# =============================================================================

class ManualGuidanceWorkflow:
    """ë§¤ë‰´ì–¼ ê°€ì´ë“œ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, orchestrator: MicroworkflowOrchestrator):
        self.orchestrator = orchestrator
    
    def build_graph(self) -> StateGraph:
        """ë§¤ë‰´ì–¼ ê°€ì´ë“œ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±"""
        
        workflow = StateGraph(ConversationState)
        
        workflow.add_node("understand_query", self.understand_query)
        workflow.add_node("search_manual", self.search_manual)
        workflow.add_node("provide_guidance", self.provide_guidance)
        workflow.add_node("check_understanding", self.check_understanding)
        workflow.add_node("provide_additional_help", self.provide_additional_help)
        
        workflow.set_entry_point("understand_query")
        workflow.add_edge("understand_query", "search_manual")
        workflow.add_edge("search_manual", "provide_guidance")
        
        workflow.add_conditional_edges(
            "provide_guidance",
            self.should_check_understanding,
            {
                "check": "check_understanding",
                "complete": END
            }
        )
        
        workflow.add_conditional_edges(
            "check_understanding",
            self.should_provide_additional_help,
            {
                "additional_help": "provide_additional_help",
                "complete": END
            }
        )
        
        workflow.add_edge("provide_additional_help", END)
        
        return workflow
    
    async def understand_query(self, state: ConversationState) -> ConversationState:
        """ì‚¬ìš©ì ì§ˆì˜ ì´í•´"""
        logger.info("Understanding user query for manual guidance")
        
        state["step_count"] += 1
        state["workflow_state"] = "understanding_query"
        
        # ì§ˆì˜ ë¶„ì„
        query_analysis = await self._analyze_user_query(state["user_input"])
        
        state["manual_guidance_state"] = {
            "query_analysis": query_analysis,
            "topic": query_analysis.get("topic", "general"),
            "complexity": query_analysis.get("complexity", "medium"),
            "analyzed_at": datetime.now().isoformat()
        }
        
        return state
    
    async def search_manual(self, state: ConversationState) -> ConversationState:
        """ë§¤ë‰´ì–¼ ê²€ìƒ‰"""
        logger.info("Searching manual database")
        
        state["step_count"] += 1
        state["workflow_state"] = "searching_manual"
        
        topic = state["manual_guidance_state"]["topic"]
        
        # ë§¤ë‰´ì–¼ ê²€ìƒ‰
        manual_results = await self.orchestrator.knowledge_engine.search(
            query=f"ë§¤ë‰´ì–¼ {topic} {state['user_input']}",
            filters={"category": "manual", "topic": topic}
        )
        
        state["retrieved_knowledge"] = manual_results
        state["manual_guidance_state"]["search_results"] = manual_results
        
        return state
    
    async def provide_guidance(self, state: ConversationState) -> ConversationState:
        """ê°€ì´ë“œ ì œê³µ"""
        logger.info("Providing manual guidance")
        
        state["step_count"] += 1
        state["workflow_state"] = "providing_guidance"
        
        # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = {
            "query": state["user_input"],
            "topic": state["manual_guidance_state"]["topic"],
            "knowledge": state["retrieved_knowledge"]
        }
        
        # ê°€ì´ë“œ ìƒì„±
        guidance_prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ë§¤ë‰´ì–¼ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
        
        ì§ˆë¬¸: {context['query']}
        ì£¼ì œ: {context['topic']}
        ê´€ë ¨ ë§¤ë‰´ì–¼ ì •ë³´: {context['knowledge']}
        
        ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ê³ , í•„ìš”ì‹œ ì£¼ì˜ì‚¬í•­ë„ í¬í•¨í•´ì£¼ì„¸ìš”.
        """
        
        guidance_response = await self.orchestrator.model_router.generate_response(
            prompt=guidance_prompt,
            context=context
        )
        
        state["generated_response"] = guidance_response["text"]
        state["manual_guidance_state"]["guidance_provided"] = True
        
        return state
    
    async def check_understanding(self, state: ConversationState) -> ConversationState:
        """ì´í•´ë„ í™•ì¸"""
        logger.info("Checking user understanding")
        
        state["step_count"] += 1
        state["workflow_state"] = "checking_understanding"
        
        # ì´í•´ë„ í™•ì¸ ì§ˆë¬¸ ìƒì„±
        understanding_check = {
            "questions": [
                "ì„¤ëª…ë“œë¦° ë‚´ìš©ì´ ëª…í™•í•˜ì…¨ë‚˜ìš”?",
                "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?",
                "ì‹¤ì œë¡œ ë”°ë¼í•´ë³´ì‹œëŠ”ë° ì–´ë ¤ì›€ì€ ì—†ìœ¼ì…¨ë‚˜ìš”?"
            ],
            "follow_up_available": True
        }
        
        state["manual_guidance_state"]["understanding_check"] = understanding_check
        
        return state
    
    async def provide_additional_help(self, state: ConversationState) -> ConversationState:
        """ì¶”ê°€ ë„ì›€ ì œê³µ"""
        logger.info("Providing additional help")
        
        state["step_count"] += 1
        state["workflow_state"] = "providing_additional_help"
        
        additional_resources = {
            "video_tutorials": ["ê¸°ë³¸ ì„¤ì • ì˜ìƒ", "ê³ ê¸‰ ê¸°ëŠ¥ ì˜ìƒ"],
            "related_topics": ["ê´€ë ¨ FAQ", "ìœ ì‚¬ ë¬¸ì œ í•´ê²°"],
            "support_options": ["ì‹¤ì‹œê°„ ì±„íŒ…", "ì „í™” ìƒë‹´", "ì›ê²© ì§€ì›"]
        }
        
        state["manual_guidance_state"]["additional_resources"] = additional_resources
        state["generated_response"] += f"\n\nğŸ“š ì¶”ê°€ ë„ì›€ë§:\n- ë™ì˜ìƒ íŠœí† ë¦¬ì–¼ ì œê³µ\n- ê´€ë ¨ FAQ í™•ì¸\n- ì‹¤ì‹œê°„ ì§€ì› ì—°ê²°"
        
        return state
    
    # ì¡°ê±´ í•¨ìˆ˜ë“¤
    def should_check_understanding(self, state: ConversationState) -> str:
        complexity = state["manual_guidance_state"]["complexity"]
        return "check" if complexity in ["medium", "high"] else "complete"
    
    def should_provide_additional_help(self, state: ConversationState) -> str:
        # ì‹¤ì œë¡œëŠ” ì‚¬ìš©ì ì‘ë‹µì„ ë°›ì•„ì„œ íŒë‹¨
        return "additional_help"  # ì‹œë®¬ë ˆì´ì…˜
    
    async def _analyze_user_query(self, user_input: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆì˜ ë¶„ì„"""
        analysis = {
            "topic": "general",
            "complexity": "medium",
            "intent": "how_to_use"
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP)
        if any(word in user_input for word in ["ì„¤ì •", "ì…‹ì—…", "ì´ˆê¸°"]):
            analysis["topic"] = "setup"
        elif any(word in user_input for word in ["ì—°ê²°", "ë„¤íŠ¸ì›Œí¬", "WiFi"]):
            analysis["topic"] = "connectivity"
        elif any(word in user_input for word in ["ê¸°ëŠ¥", "ì‚¬ìš©", "ì¡°ì‘"]):
            analysis["topic"] = "operation"
        
        return analysis

# =============================================================================
# Purchase Guide Workflow
# =============================================================================

class PurchaseGuideWorkflow:
    """êµ¬ë§¤ ê°€ì´ë“œ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, orchestrator: MicroworkflowOrchestrator):
        self.orchestrator = orchestrator
    
    def build_graph(self) -> StateGraph:
        """êµ¬ë§¤ ê°€ì´ë“œ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±"""
        
        workflow = StateGraph(ConversationState)
        
        workflow.add_node("assess_needs", self.assess_needs)
        workflow.add_node("build_compatibility_matrix", self.build_compatibility_matrix)
        workflow.add_node("generate_recommendations", self.generate_recommendations)
        workflow.add_node("provide_comparison", self.provide_comparison)
        workflow.add_node("assist_purchase", self.assist_purchase)
        
        workflow.set_entry_point("assess_needs")
        workflow.add_edge("assess_needs", "build_compatibility_matrix")
        workflow.add_edge("build_compatibility_matrix", "generate_recommendations")
        workflow.add_edge("generate_recommendations", "provide_comparison")
        workflow.add_edge("provide_comparison", "assist_purchase")
        workflow.add_edge("assist_purchase", END)
        
        return workflow
    
    async def assess_needs(self, state: ConversationState) -> ConversationState:
        """ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ í‰ê°€"""
        logger.info("Assessing user needs for purchase guide")
        
        state["step_count"] += 1
        state["workflow_state"] = "assessing_needs"
        
        # ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
        needs_analysis = await self._extract_purchase_requirements(state["user_input"])
        
        state["purchase_guide_state"] = {
            "needs_analysis": needs_analysis,
            "budget_range": needs_analysis.get("budget", "medium"),
            "use_cases": needs_analysis.get("use_cases", []),
            "preferences": needs_analysis.get("preferences", {}),
            "assessed_at": datetime.now().isoformat()
        }
        
        return state
    
    async def build_compatibility_matrix(self, state: ConversationState) -> ConversationState:
        """í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±"""
        logger.info("Building compatibility matrix")
        
        state["step_count"] += 1
        state["workflow_state"] = "building_compatibility"
        
        user_devices = state["device_info"]
        needs = state["purchase_guide_state"]["needs_analysis"]
        
        # í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        compatibility_matrix = {
            "current_ecosystem": self._analyze_ecosystem(user_devices),
            "compatible_brands": ["Samsung", "LG", "Philips"],
            "compatibility_score": {},
            "requirements": needs.get("requirements", {})
        }
        
        state["purchase_guide_state"]["compatibility_matrix"] = compatibility_matrix
        
        return state
    
    async def generate_recommendations(self, state: ConversationState) -> ConversationState:
        """ì¶”ì²œ ì œí’ˆ ìƒì„±"""
        logger.info("Generating product recommendations")
        
        state["step_count"] += 1
        state["workflow_state"] = "generating_recommendations"
        
        compatibility = state["purchase_guide_state"]["compatibility_matrix"]
        needs = state["purchase_guide_state"]["needs_analysis"]
        
        # ì¶”ì²œ ì œí’ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        recommendations = [
            {
                "product_id": "smart_cam_001",
                "name": "SmartCam Pro 2024",
                "brand": "Samsung",
                "price": 150000,
                "compatibility_score": 95,
                "features": ["4K recording", "Night vision", "Smart alerts"],
                "pros": ["High quality", "Easy setup", "Good app"],
                "cons": ["Pricey", "Requires subscription for cloud"]
            },
            {
                "product_id": "smart_cam_002", 
                "name": "HomeCam Essential",
                "brand": "LG",
                "price": 89000,
                "compatibility_score": 88,
                "features": ["1080p recording", "Motion detection", "Local storage"],
                "pros": ["Affordable", "No subscription", "Reliable"],
                "cons": ["Lower resolution", "Basic features"]
            }
        ]
        
        state["purchase_guide_state"]["recommendations"] = recommendations
        
        return state
    
    async def provide_comparison(self, state: ConversationState) -> ConversationState:
        """ì œí’ˆ ë¹„êµ ì œê³µ"""
        logger.info("Providing product comparison")
        
        state["step_count"] += 1
        state["workflow_state"] = "providing_comparison"
        
        recommendations = state["purchase_guide_state"]["recommendations"]
        
        # ë¹„êµí‘œ ìƒì„±
        comparison_prompt = f"""
        ë‹¤ìŒ ì¶”ì²œ ì œí’ˆë“¤ì„ ì‚¬ìš©ìê°€ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ í‘œë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
        
        {json.dumps(recommendations, ensure_ascii=False, indent=2)}
        
        ê°€ê²©, ê¸°ëŠ¥, í˜¸í™˜ì„±, ì¥ë‹¨ì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¹„êµí•´ì£¼ì„¸ìš”.
        """
        
        comparison_response = await self.orchestrator.model_router.generate_response(
            prompt=comparison_prompt,
            context={"recommendations": recommendations}
        )
        
        state["generated_response"] = comparison_response["text"]
        state["purchase_guide_state"]["comparison_provided"] = True
        
        return state
    
    async def assist_purchase(self, state: ConversationState) -> ConversationState:
        """êµ¬ë§¤ ì§€ì›"""
        logger.info("Assisting with purchase")
        
        state["step_count"] += 1
        state["workflow_state"] = "assisting_purchase"
        
        recommendations = state["purchase_guide_state"]["recommendations"]
        
        # êµ¬ë§¤ ì§€ì› ì •ë³´
        purchase_assistance = {
            "online_stores": ["ì¿ íŒ¡", "ë„¤ì´ë²„ì‡¼í•‘", "11ë²ˆê°€"],
            "offline_stores": ["í•˜ì´ë§ˆíŠ¸", "ì „ìëœë“œ", "ë¡¯ë°í•˜ì´ë§ˆíŠ¸"],
            "discount_info": "í˜„ì¬ ì§„í–‰ì¤‘ì¸ í• ì¸ ì´ë²¤íŠ¸ í™•ì¸",
            "installation_service": "ì „ë¬¸ ì„¤ì¹˜ ì„œë¹„ìŠ¤ ì´ìš© ê°€ëŠ¥"
        }
        
        state["purchase_guide_state"]["purchase_assistance"] = purchase_assistance
        
        # êµ¬ë§¤ ë§í¬ ë° ì¶”ê°€ ì •ë³´ ì œê³µ
        purchase_actions = []
        for product in recommendations:
            purchase_actions.append({
                "type": "product_link",
                "description": f"{product['name']} êµ¬ë§¤í•˜ê¸°",
                "data": {
                    "product_id": product["product_id"],
                    "name": product["name"],
                    "price": product["price"]
                }
            })
        
        state["required_actions"] = purchase_actions
        state["generated_response"] += f"\n\nğŸ›’ êµ¬ë§¤ ì§€ì›:\n- ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ ë§¤ì¥ ì•ˆë‚´\n- í• ì¸ ì •ë³´ í™•ì¸\n- ì„¤ì¹˜ ì„œë¹„ìŠ¤ ì—°ê²°"
        
        return state
    
    async def _extract_purchase_requirements(self, user_input: str) -> Dict[str, Any]:
        """êµ¬ë§¤ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ"""
        requirements = {
            "budget": "medium",
            "use_cases": ["home_security"],
            "preferences": {},
            "requirements": {}
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ
        if "ì €ë ´" in user_input or "ì‹¼" in user_input:
            requirements["budget"] = "low"
        elif "ê³ ê¸‰" in user_input or "í”„ë¦¬ë¯¸ì—„" in user_input:
            requirements["budget"] = "high"
            
        if "ë³´ì•ˆ" in user_input or "ê°ì‹œ" in user_input:
            requirements["use_cases"].append("security")
        if "ë°˜ë ¤ë™ë¬¼" in user_input or "í«" in user_input:
            requirements["use_cases"].append("pet_monitoring")
            
        return requirements
    
    def _analyze_ecosystem(self, device_info: Dict) -> Dict[str, Any]:
        """ê¸°ì¡´ ë””ë°”ì´ìŠ¤ ìƒíƒœê³„ ë¶„ì„"""
        ecosystem = {
            "primary_platform": "android",  # device_infoì—ì„œ ì¶”ì¶œ
            "existing_smart_devices": [],
            "preferred_brands": [],
            "integration_level": "basic"
        }
        
        if device_info.get("os") == "iOS":
            ecosystem["primary_platform"] = "ios"
            ecosystem["preferred_brands"].append("Apple")
        
        return ecosystem

# =============================================================================
# Supporting Services (Mock Implementations)
# =============================================================================

class AdaptiveModelRouter:
    """ì ì‘í˜• ëª¨ë¸ ë¼ìš°í„° (Mock)"""
    
    async def generate_response(self, prompt: str, context: Dict = None) -> Dict[str, Any]:
        """ì‘ë‹µ ìƒì„± (Mock)"""
        # ì‹¤ì œë¡œëŠ” vLLM, Ollama, ë˜ëŠ” ì™¸ë¶€ API í˜¸ì¶œ
        return {
            "text": f"Generated response for: {prompt[:50]}...",
            "model_used": "gemma-7b",
            "tokens": 150,
            "cost": 0.001
        }

class KnowledgeEngine:
    """ì§€ì‹ ê²€ìƒ‰ ì—”ì§„ (Mock)"""
    
    async def search(self, query: str, filters: Dict = None) -> List[Dict[str, Any]]:
        """ì§€ì‹ ê²€ìƒ‰ (Mock)"""
        # ì‹¤ì œë¡œëŠ” FAISS + GraphRAG ê²€ìƒ‰
        return [
            {
                "id": "doc_001",
                "title": f"ê´€ë ¨ ë¬¸ì„œ - {query}",
                "content": f"ì´ê²ƒì€ {query}ì— ê´€í•œ ë‚´ìš©ì…ë‹ˆë‹¤...",
                "score": 0.85,
                "source": "manual_database"
            }
        ]

# =============================================================================
# FastAPI Integration
# =============================================================================

from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel

class ChatRequest(BaseModel):
    user_input: str
    user_id: str
    session_id: Optional[str] = None
    device_info: Dict[str, Any]

class ChatResponse(BaseModel):
    conversation_id: str
    response: str
    actions: List[Dict[str, Any]]
    workflow_type: Optional[str]
    success: bool

app = FastAPI(title="IoT AI Chatbot Orchestrator")

# ì „ì—­ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì¸ìŠ¤í„´ìŠ¤
orchestrator = None

@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì‹œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”"""
    global orchestrator
    
    # Redis, Kafka ë“± ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²°
    redis_client = Redis(host="localhost", port=6379, decode_responses=True)
    kafka_producer = KafkaProducer(bootstrap_servers=['localhost:9092'])
    model_router = AdaptiveModelRouter()
    knowledge_engine = KnowledgeEngine()
    
    orchestrator = MicroworkflowOrchestrator(
        redis_client=redis_client,
        kafka_producer=kafka_producer, 
        model_router=model_router,
        knowledge_engine=knowledge_engine
    )
    
    logger.info("Orchestrator initialized successfully")

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest, background_tasks: BackgroundTasks):
    """ë©”ì¸ ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    
    if not orchestrator:
        raise HTTPException(status_code=500, detail="Orchestrator not initialized")
    
    try:
        result = await orchestrator.process_user_request(
            user_input=request.user_input,
            user_id=request.user_id,
            device_info=request.device_info,
            session_id=request.session_id
        )
        
        return ChatResponse(**result)
        
    except Exception as e:
        logger.error(f"Chat endpoint error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "workflows": orchestrator.workflow_registry.list_workflows() if orchestrator else []
    }

@app.get("/workflows")
async def list_workflows():
    """ë“±ë¡ëœ ì›Œí¬í”Œë¡œìš° ëª©ë¡"""
    if not orchestrator:
        raise HTTPException(status_code=500, detail="Orchestrator not initialized")
        
    return {
        "workflows": orchestrator.workflow_registry.list_workflows(),
        "count": len(orchestrator.workflow_registry.workflows)
    }

if __name__ == "__main__":
    import uvicorn
    
    # ê°œë°œìš© ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "orchestrator:app",
        host="0.0.0.0", 
        port=8000,
        reload=True,
        log_level="info"
    )